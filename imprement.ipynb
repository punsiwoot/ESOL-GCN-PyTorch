{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#import estential tool\n",
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "import torch_geometric\n",
    "from torch_geometric.datasets import MoleculeNet\n",
    "from torch_geometric.data import Data\n",
    "import networkx as nx\n",
    "import seaborn as sb\n",
    "import sklearn\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#for trainning\n",
    "from torch_geometric.data import DataLoader\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import torch\n",
    "from torch.nn import Linear\n",
    "from torch.nn import init\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, TopKPooling, global_mean_pool\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utill import *\n",
    "from Model.BASE_model import *\n",
    "from Model.Less_layer_model import *\n",
    "from Model.More_layer_model import *\n",
    "from Model.BASE_model_tanh import *\n",
    "from Model.Less_layer_model_tanh import *\n",
    "from Model.More_layer_model_tanh import *\n",
    "from Model.BASE_model_tanh_pyra import *\n",
    "from Model.Less_layer_model_tanh_pyra import *\n",
    "from Model.More_layer_model_tanh_pyra import *\n",
    "from Model.BASE_model_pyra import *\n",
    "from Model.Less_layer_model_pyra import *\n",
    "from Model.More_layer_model_pyra import *\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "seed_value = 42\n",
    "torch.manual_seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# Download dataset\n",
    "data = MoleculeNet(root=\".\", name=\"ESOL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup dataset\n",
    "data_size = len(data)\n",
    "NUM_GRAPHS_PER_BATCH = 32\n",
    "training_set = DataLoader(data[:int(data_size * 0.7)],\n",
    "                    batch_size=NUM_GRAPHS_PER_BATCH, shuffle=False)\n",
    "test_set = DataLoader(data[int(data_size * 0.7):int(data_size * 0.85)],\n",
    "                         batch_size=NUM_GRAPHS_PER_BATCH, shuffle=False)\n",
    "validation_set = DataLoader(data[int(data_size * 0.85):],\n",
    "                         batch_size=NUM_GRAPHS_PER_BATCH, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first set\n",
    "# setup \n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "#first model\n",
    "first_model = GCN_BASE_model(data_num_features=data.num_features, embedding_size=32)\n",
    "PATH_first_model_init = \"Save_weight/init_weight/first_model.pth\"\n",
    "# first_model.init_weights()\n",
    "# torch.save(first_model.state_dict(), PATH_first_model_init)\n",
    "first_model.load_state_dict(torch.load(PATH_first_model_init))\n",
    "optimizer_first = torch.optim.Adam(first_model.parameters(), lr=0.0007)\n",
    "\n",
    "#second model\n",
    "second_model = GCN_BASE_model(data_num_features=data.num_features, embedding_size=64)\n",
    "PATH_second_model_init = \"Save_weight/init_weight/second_model.pth\"\n",
    "# second_model.init_weights()\n",
    "# torch.save(second_model.state_dict(), PATH_second_model_init)\n",
    "second_model.load_state_dict(torch.load(PATH_second_model_init))\n",
    "optimizer_second = torch.optim.Adam(second_model.parameters(), lr=0.0007)\n",
    "\n",
    "#third model\n",
    "third_model = GCN_BASE_model(data_num_features=data.num_features, embedding_size=128)\n",
    "PATH_third_model_init = \"Save_weight/init_weight/third_model.pth\"\n",
    "# third_model.init_weights()\n",
    "# torch.save(third_model.state_dict(), PATH_third_model_init)\n",
    "third_model.load_state_dict(torch.load(PATH_third_model_init))\n",
    "optimizer_third = torch.optim.Adam(third_model.parameters(), lr=0.0007)\n",
    "\n",
    "#forth model\n",
    "forth_model = GCN_More_layer_model(data_num_features=data.num_features, embedding_size=32)\n",
    "PATH_forth_model_init = \"Save_weight/init_weight/forth_model.pth\"\n",
    "# forth_model.init_weights()\n",
    "# torch.save(forth_model.state_dict(), PATH_forth_model_init)\n",
    "forth_model.load_state_dict(torch.load(PATH_forth_model_init))\n",
    "optimizer_forth = torch.optim.Adam(forth_model.parameters(), lr=0.0007)\n",
    "\n",
    "#fifth model\n",
    "fifth_model = GCN_More_layer_model(data_num_features=data.num_features, embedding_size=64)\n",
    "PATH_fifth_model_init = \"Save_weight/init_weight/fifth_model.pth\"\n",
    "# fifth_model.init_weights()\n",
    "# torch.save(fifth_model.state_dict(), PATH_fifth_model_init)\n",
    "fifth_model.load_state_dict(torch.load(PATH_fifth_model_init))\n",
    "optimizer_fifth = torch.optim.Adam(fifth_model.parameters(), lr=0.0007)\n",
    "\n",
    "#sixth model\n",
    "sixth_model = GCN_More_layer_model(data_num_features=data.num_features, embedding_size=128)\n",
    "PATH_sixth_model_init = \"Save_weight/init_weight/sixth_model.pth\"\n",
    "# sixth_model.init_weights()\n",
    "# torch.save(sixth_model.state_dict(), PATH_sixth_model_init)\n",
    "sixth_model.load_state_dict(torch.load(PATH_sixth_model_init))\n",
    "optimizer_sixth = torch.optim.Adam(sixth_model.parameters(), lr=0.0007)\n",
    "\n",
    "#seventh model\n",
    "seventh_model = GCN_Less_layer_model(data_num_features=data.num_features, embedding_size=32)\n",
    "PATH_seventh_model_init = \"Save_weight/init_weight/seventh_model.pth\"\n",
    "# seventh_model.init_weights()\n",
    "# torch.save(seventh_model.state_dict(), PATH_seventh_model_init)\n",
    "seventh_model.load_state_dict(torch.load(PATH_seventh_model_init))\n",
    "optimizer_seventh = torch.optim.Adam(seventh_model.parameters(), lr=0.0007)\n",
    "\n",
    "#eighth model\n",
    "eighth_model = GCN_Less_layer_model(data_num_features=data.num_features, embedding_size=64)\n",
    "PATH_eighth_model_init = \"Save_weight/init_weight/eighth_model.pth\"\n",
    "# eighth_model.init_weights()\n",
    "# torch.save(eighth_model.state_dict(), PATH_eighth_model_init)\n",
    "eighth_model.load_state_dict(torch.load(PATH_eighth_model_init))\n",
    "optimizer_eighth = torch.optim.Adam(eighth_model.parameters(), lr=0.0007)\n",
    "\n",
    "#ninth model\n",
    "ninth_model = GCN_Less_layer_model(data_num_features=data.num_features, embedding_size=128)\n",
    "PATH_ninth_model_init = \"Save_weight/init_weight/ninth_model.pth\"\n",
    "# ninth_model.init_weights()\n",
    "# torch.save(ninth_model.state_dict(), PATH_ninth_model_init)\n",
    "ninth_model.load_state_dict(torch.load(PATH_ninth_model_init))\n",
    "optimizer_ninth = torch.optim.Adam(ninth_model.parameters(), lr=0.0007)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # first_model trainning\n",
    "# loss_fn = torch.nn.MSELoss()\n",
    "# first_model = GCN_BASE_model_tanh(data_num_features=data.num_features, embedding_size=32)\n",
    "# first_model.load_state_dict(torch.load(PATH_first_model_init))\n",
    "# optimizer_first = torch.optim.Adam(first_model.parameters(), lr=0.0007)\n",
    "# loss_train_track_first, loss_valid_track_first, stop_at_epoch_first = train(model=first_model, optimizer=optimizer_first, loss_fn=loss_fn,\n",
    "#                                                                             epochs=5, is_early_stop=False, show_result_at=1,\n",
    "#                                                                             device=device, validation_set=validation_set, training_set=training_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first model\n",
    "first_model = GCN_BASE_model(data_num_features=data.num_features, embedding_size=32).to(device)\n",
    "PATH_first_model_init = \"Save_weight/init_weight/first_model.pth\"\n",
    "# first_model.init_weights()\n",
    "# torch.save(first_model.state_dict(), PATH_first_model_init)\n",
    "first_model.load_state_dict(torch.load(PATH_first_model_init))\n",
    "optimizer_first = torch.optim.Adam(first_model.parameters(), lr=0.0007)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at epoch : 1 train_loss = 1310.6520776367188  valid_loss = 433.23113505045575\n",
      "at epoch : 2 train_loss = 212.87633819580077  valid_loss = 212.7928899129232\n",
      "at epoch : 3 train_loss = 145.24710052490235  valid_loss = 145.94114303588867\n",
      "at epoch : 4 train_loss = 121.67669036865234  valid_loss = 124.27682113647461\n",
      "at epoch : 5 train_loss = 107.7506118774414  valid_loss = 110.82983271280925\n",
      "at epoch : 6 train_loss = 95.63193283081054  valid_loss = 97.61493873596191\n",
      "at epoch : 7 train_loss = 83.68597747802734  valid_loss = 84.0013821919759\n",
      "at epoch : 8 train_loss = 72.77913497924804  valid_loss = 72.19316418965657\n",
      "at epoch : 9 train_loss = 64.29444137573242  valid_loss = 64.05376402537028\n",
      "at epoch : 10 train_loss = 58.01697982788086  valid_loss = 57.81423314412435\n",
      "at epoch : 11 train_loss = 52.866600036621094  valid_loss = 52.585845947265625\n",
      "at epoch : 12 train_loss = 48.46156234741211  valid_loss = 48.0396925608317\n",
      "at epoch : 13 train_loss = 44.566526641845705  valid_loss = 44.0296246210734\n",
      "at epoch : 14 train_loss = 41.01807769775391  valid_loss = 40.383249282836914\n",
      "at epoch : 15 train_loss = 37.74138542175293  valid_loss = 36.970470110575356\n",
      "at epoch : 16 train_loss = 34.45377326965332  valid_loss = 33.415855407714844\n",
      "at epoch : 17 train_loss = 30.721476211547852  valid_loss = 29.55600643157959\n",
      "at epoch : 18 train_loss = 27.08672752380371  valid_loss = 26.368060906728108\n",
      "at epoch : 19 train_loss = 24.395294303894044  valid_loss = 24.062406222025555\n",
      "at epoch : 20 train_loss = 22.342777938842772  valid_loss = 22.18146864573161\n",
      "at epoch : 21 train_loss = 20.82831142425537  valid_loss = 20.5992218653361\n",
      "at epoch : 22 train_loss = 19.516937255859375  valid_loss = 19.267804940541584\n",
      "at epoch : 23 train_loss = 18.32539653778076  valid_loss = 18.04398012161255\n",
      "at epoch : 24 train_loss = 17.234178085327148  valid_loss = 16.938119252522785\n",
      "at epoch : 25 train_loss = 16.23914333343506  valid_loss = 15.939491430918375\n",
      "at epoch : 26 train_loss = 15.327633285522461  valid_loss = 15.032256285349527\n",
      "at epoch : 27 train_loss = 14.4943217086792  valid_loss = 14.205352465311686\n",
      "at epoch : 28 train_loss = 13.728566722869873  valid_loss = 13.45967165629069\n",
      "at epoch : 29 train_loss = 13.034731044769288  valid_loss = 12.780784368515015\n",
      "at epoch : 30 train_loss = 12.404651432037353  valid_loss = 12.168743371963501\n"
     ]
    }
   ],
   "source": [
    "#first section train\n",
    "epoch = 30\n",
    "save_at = 5\n",
    "continue_at = 0\n",
    "# first_model trainning\n",
    "PATH_to_esol_drive = \"Debug/\"\n",
    "first_model = GCN_BASE_model(data_num_features=data.num_features, embedding_size=32).to(device)\n",
    "first_model.load_state_dict(torch.load(PATH_first_model_init))\n",
    "# first_model.load_state_dict(torch.load(\"Debug/first_model_e5.pth\"))\n",
    "\n",
    "optimizer_first = torch.optim.Adam(first_model.parameters(), lr=0.0007)\n",
    "# optimizer_first.load_state_dict(torch.load(\"Debug/first_modeloptimizer_e5.pth\"))\n",
    "loss_train_track_first, loss_valid_track_first, stop_at_epoch_first = train(model=first_model, optimizer=optimizer_first, loss_fn=loss_fn,\n",
    "                                                                            epochs=epoch, is_early_stop=False, show_result_at=1,\n",
    "                                                                            device=device, validation_set=validation_set, training_set=training_set,\n",
    "                                                                            save_path = PATH_to_esol_drive,save_every=save_at,is_auto_save=True,model_name=\"first_model\",\n",
    "                                                                            continue_epoch=continue_at)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at epoch : 1 train_loss = 1310.6520776367188  valid_loss = 433.23113505045575\n",
      "at epoch : 2 train_loss = 212.87633819580077  valid_loss = 212.7928899129232\n",
      "at epoch : 3 train_loss = 145.24710052490235  valid_loss = 145.94114303588867\n",
      "at epoch : 4 train_loss = 121.67669036865234  valid_loss = 124.27682113647461\n",
      "at epoch : 5 train_loss = 107.7506118774414  valid_loss = 110.82983271280925\n",
      "at epoch : 6 train_loss = 95.63193283081054  valid_loss = 97.61493873596191\n",
      "at epoch : 7 train_loss = 83.68597747802734  valid_loss = 84.0013821919759\n",
      "at epoch : 8 train_loss = 72.77913497924804  valid_loss = 72.19316418965657\n",
      "at epoch : 9 train_loss = 64.29444137573242  valid_loss = 64.05376402537028\n",
      "at epoch : 10 train_loss = 58.01697982788086  valid_loss = 57.81423314412435\n",
      "at epoch : 11 train_loss = 52.866600036621094  valid_loss = 52.585845947265625\n",
      "at epoch : 12 train_loss = 48.46156234741211  valid_loss = 48.0396925608317\n",
      "at epoch : 13 train_loss = 44.566526641845705  valid_loss = 44.0296246210734\n",
      "at epoch : 14 train_loss = 41.01807769775391  valid_loss = 40.383249282836914\n",
      "at epoch : 15 train_loss = 37.74138542175293  valid_loss = 36.970470110575356\n",
      "at epoch : 16 train_loss = 34.45377326965332  valid_loss = 33.415855407714844\n",
      "at epoch : 17 train_loss = 30.721476211547852  valid_loss = 29.55600643157959\n",
      "at epoch : 18 train_loss = 27.08672752380371  valid_loss = 26.368060906728108\n",
      "at epoch : 19 train_loss = 24.395294303894044  valid_loss = 24.062406222025555\n",
      "at epoch : 20 train_loss = 22.342777938842772  valid_loss = 22.18146864573161\n",
      "at epoch : 21 train_loss = 20.82831142425537  valid_loss = 20.5992218653361\n",
      "at epoch : 22 train_loss = 19.516937255859375  valid_loss = 19.267804940541584\n",
      "at epoch : 23 train_loss = 18.32539653778076  valid_loss = 18.04398012161255\n",
      "at epoch : 24 train_loss = 17.234178085327148  valid_loss = 16.938119252522785\n",
      "at epoch : 25 train_loss = 16.23914333343506  valid_loss = 15.939491430918375\n",
      "at epoch : 26 train_loss = 15.327633285522461  valid_loss = 15.032256285349527\n",
      "at epoch : 27 train_loss = 14.4943217086792  valid_loss = 14.205352465311686\n",
      "at epoch : 28 train_loss = 13.728566722869873  valid_loss = 13.45967165629069\n",
      "at epoch : 29 train_loss = 13.034731044769288  valid_loss = 12.780784368515015\n",
      "at epoch : 30 train_loss = 12.404651432037353  valid_loss = 12.168743371963501\n"
     ]
    }
   ],
   "source": [
    "#first section train\n",
    "epoch = 30\n",
    "save_at = 0\n",
    "continue_at = 0\n",
    "# first_model trainning\n",
    "PATH_to_esol_drive = \"Debug/\"\n",
    "first_model_test = GCN_BASE_model(data_num_features=data.num_features, embedding_size=32).to(device)\n",
    "first_model_test.load_state_dict(torch.load(PATH_first_model_init))\n",
    "# first_model_test.load_state_dict(torch.load(\"Debug/first_model_e30.pth\"))\n",
    "\n",
    "optimizer_first_test = torch.optim.Adam(first_model_test.parameters(), lr=0.0007)\n",
    "# optimizer_first_test.load_state_dict(torch.load(\"Debug/first_modeloptimizer_e30.pth\"))\n",
    "loss_train_track_first, loss_valid_track_first, stop_at_epoch_first = train(model=first_model_test, optimizer=optimizer_first_test, loss_fn=loss_fn,\n",
    "                                                                            epochs=epoch, is_early_stop=False, show_result_at=1,\n",
    "                                                                            device=device, validation_set=validation_set, training_set=training_set,\n",
    "                                                                            save_path = PATH_to_esol_drive,save_every=save_at,is_auto_save=True,model_name=\"first_model\",\n",
    "                                                                            continue_epoch=continue_at)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.816683451334637\n",
      "17.816683451334637\n"
     ]
    }
   ],
   "source": [
    "print(test(model=first_model,loss_fn=loss_fn,test_set=test_set,device=device))\n",
    "print(test(model=first_model_test,loss_fn=loss_fn,test_set=test_set,device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "17.816683451334637\n",
    "17.62319215138753"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[379, 9], edge_index=[2, 774], edge_attr=[774, 3], smiles=[32], y=[32, 1], batch=[379], ptr=[33])\n",
      "DataBatch(x=[459, 9], edge_index=[2, 970], edge_attr=[970, 3], smiles=[32], y=[32, 1], batch=[459], ptr=[33])\n",
      "DataBatch(x=[421, 9], edge_index=[2, 858], edge_attr=[858, 3], smiles=[32], y=[32, 1], batch=[421], ptr=[33])\n",
      "DataBatch(x=[451, 9], edge_index=[2, 922], edge_attr=[922, 3], smiles=[32], y=[32, 1], batch=[451], ptr=[33])\n",
      "DataBatch(x=[444, 9], edge_index=[2, 934], edge_attr=[934, 3], smiles=[32], y=[32, 1], batch=[444], ptr=[33])\n",
      "DataBatch(x=[411, 9], edge_index=[2, 846], edge_attr=[846, 3], smiles=[32], y=[32, 1], batch=[411], ptr=[33])\n",
      "DataBatch(x=[369, 9], edge_index=[2, 754], edge_attr=[754, 3], smiles=[32], y=[32, 1], batch=[369], ptr=[33])\n",
      "DataBatch(x=[467, 9], edge_index=[2, 962], edge_attr=[962, 3], smiles=[32], y=[32, 1], batch=[467], ptr=[33])\n",
      "DataBatch(x=[444, 9], edge_index=[2, 936], edge_attr=[936, 3], smiles=[32], y=[32, 1], batch=[444], ptr=[33])\n",
      "DataBatch(x=[455, 9], edge_index=[2, 952], edge_attr=[952, 3], smiles=[32], y=[32, 1], batch=[455], ptr=[33])\n",
      "DataBatch(x=[441, 9], edge_index=[2, 926], edge_attr=[926, 3], smiles=[32], y=[32, 1], batch=[441], ptr=[33])\n",
      "DataBatch(x=[382, 9], edge_index=[2, 788], edge_attr=[788, 3], smiles=[32], y=[32, 1], batch=[382], ptr=[33])\n",
      "DataBatch(x=[400, 9], edge_index=[2, 814], edge_attr=[814, 3], smiles=[32], y=[32, 1], batch=[400], ptr=[33])\n",
      "DataBatch(x=[378, 9], edge_index=[2, 770], edge_attr=[770, 3], smiles=[32], y=[32, 1], batch=[378], ptr=[33])\n",
      "DataBatch(x=[400, 9], edge_index=[2, 820], edge_attr=[820, 3], smiles=[32], y=[32, 1], batch=[400], ptr=[33])\n",
      "DataBatch(x=[410, 9], edge_index=[2, 828], edge_attr=[828, 3], smiles=[32], y=[32, 1], batch=[410], ptr=[33])\n",
      "DataBatch(x=[430, 9], edge_index=[2, 890], edge_attr=[890, 3], smiles=[32], y=[32, 1], batch=[430], ptr=[33])\n",
      "DataBatch(x=[393, 9], edge_index=[2, 806], edge_attr=[806, 3], smiles=[32], y=[32, 1], batch=[393], ptr=[33])\n",
      "DataBatch(x=[381, 9], edge_index=[2, 766], edge_attr=[766, 3], smiles=[32], y=[32, 1], batch=[381], ptr=[33])\n",
      "DataBatch(x=[439, 9], edge_index=[2, 908], edge_attr=[908, 3], smiles=[32], y=[32, 1], batch=[439], ptr=[33])\n",
      "DataBatch(x=[466, 9], edge_index=[2, 980], edge_attr=[980, 3], smiles=[32], y=[32, 1], batch=[466], ptr=[33])\n",
      "DataBatch(x=[455, 9], edge_index=[2, 920], edge_attr=[920, 3], smiles=[32], y=[32, 1], batch=[455], ptr=[33])\n",
      "DataBatch(x=[401, 9], edge_index=[2, 812], edge_attr=[812, 3], smiles=[32], y=[32, 1], batch=[401], ptr=[33])\n",
      "DataBatch(x=[450, 9], edge_index=[2, 930], edge_attr=[930, 3], smiles=[32], y=[32, 1], batch=[450], ptr=[33])\n",
      "DataBatch(x=[359, 9], edge_index=[2, 760], edge_attr=[760, 3], smiles=[21], y=[21, 1], batch=[359], ptr=[22])\n"
     ]
    }
   ],
   "source": [
    "for i in training_set:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[447, 9], edge_index=[2, 932], edge_attr=[932, 3], smiles=[32], y=[32, 1], batch=[447], ptr=[33])\n",
      "DataBatch(x=[426, 9], edge_index=[2, 886], edge_attr=[886, 3], smiles=[32], y=[32, 1], batch=[426], ptr=[33])\n",
      "DataBatch(x=[467, 9], edge_index=[2, 972], edge_attr=[972, 3], smiles=[32], y=[32, 1], batch=[467], ptr=[33])\n",
      "DataBatch(x=[394, 9], edge_index=[2, 794], edge_attr=[794, 3], smiles=[32], y=[32, 1], batch=[394], ptr=[33])\n",
      "DataBatch(x=[404, 9], edge_index=[2, 824], edge_attr=[824, 3], smiles=[32], y=[32, 1], batch=[404], ptr=[33])\n",
      "DataBatch(x=[111, 9], edge_index=[2, 222], edge_attr=[222, 3], smiles=[9], y=[9, 1], batch=[111], ptr=[10])\n"
     ]
    }
   ],
   "source": [
    "for i in test_set :\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[408, 9], edge_index=[2, 852], edge_attr=[852, 3], smiles=[32], y=[32, 1], batch=[408], ptr=[33])\n",
      "DataBatch(x=[409, 9], edge_index=[2, 840], edge_attr=[840, 3], smiles=[32], y=[32, 1], batch=[409], ptr=[33])\n",
      "DataBatch(x=[455, 9], edge_index=[2, 934], edge_attr=[934, 3], smiles=[32], y=[32, 1], batch=[455], ptr=[33])\n",
      "DataBatch(x=[427, 9], edge_index=[2, 866], edge_attr=[866, 3], smiles=[32], y=[32, 1], batch=[427], ptr=[33])\n",
      "DataBatch(x=[435, 9], edge_index=[2, 902], edge_attr=[902, 3], smiles=[32], y=[32, 1], batch=[435], ptr=[33])\n",
      "DataBatch(x=[115, 9], edge_index=[2, 236], edge_attr=[236, 3], smiles=[9], y=[9, 1], batch=[115], ptr=[10])\n"
     ]
    }
   ],
   "source": [
    "for i in test_set :\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.093841870625814"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "14.86410919825236\n",
    "15.093841870625814"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([ 0.0126, -0.0116,  0.0000,  0.0095,  0.0170,  0.0000,  0.0000,  0.0122,\n",
      "         0.0000, -0.0073,  0.0087,  0.0000,  0.0000,  0.0112,  0.0000, -0.0126,\n",
      "         0.0303,  0.0030,  0.0000,  0.0000, -0.0145,  0.0000,  0.0167,  0.0000,\n",
      "         0.0000,  0.0056,  0.0112,  0.0112,  0.0036, -0.0076,  0.0000, -0.0100],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 9.9713e-01,  1.3733e+00, -3.1562e-01, -5.2806e-01,  5.4191e-01,\n",
      "         -1.1346e+00,  4.8438e-01, -7.0008e-01,  4.5105e-01],\n",
      "        [ 5.5859e-01,  2.4628e-01,  2.8755e+00, -5.6728e-01, -4.6676e-03,\n",
      "         -3.9583e-01,  3.9306e-01,  1.5500e-01, -2.7219e+00],\n",
      "        [-1.2835e-01, -4.4340e-01, -1.7999e+00, -4.8732e-01, -3.6020e-01,\n",
      "         -8.5379e-01,  1.3559e+00, -6.2743e-01,  4.7283e-01],\n",
      "        [-6.7590e-01,  1.4168e+00,  8.6890e-01,  8.9256e-01, -8.8550e-01,\n",
      "         -1.3402e+00,  4.4579e-02, -4.4704e-01,  1.3631e-01],\n",
      "        [ 1.6322e+00, -4.2968e-01, -1.2002e-01,  3.1908e-01, -9.5652e-01,\n",
      "          2.9410e-01, -3.3934e-01, -1.3381e-01, -7.2239e-02],\n",
      "        [-1.9935e+00,  1.1608e-01,  1.3771e+00,  8.5450e-01, -1.1794e+00,\n",
      "         -9.5405e-01, -9.6967e-01,  3.1414e-01,  1.2000e+00],\n",
      "        [-1.8317e-01,  4.2561e-01, -1.0347e-01, -1.0870e-01,  5.7822e-01,\n",
      "          1.7500e+00,  2.0350e-03,  3.6501e-01, -8.9467e-01],\n",
      "        [ 1.1870e+00,  1.1797e+00,  8.3901e-01,  1.4699e+00, -1.0065e+00,\n",
      "         -1.2957e+00,  2.9701e-01, -2.1987e+00,  8.3223e-01],\n",
      "        [-1.2931e+00,  4.5108e-01, -3.9537e-01,  1.7162e+00,  1.5393e-01,\n",
      "         -1.4652e+00, -5.1707e-01, -3.5225e-01, -8.1010e-01],\n",
      "        [ 6.7270e-01,  3.3716e-01, -5.3640e-01,  9.2520e-01,  6.6032e-01,\n",
      "          1.4379e-01, -5.4495e-01,  3.5628e-02,  2.2501e-01],\n",
      "        [ 2.3985e+00,  4.0238e-01,  1.6965e+00, -2.7353e+00, -1.8834e+00,\n",
      "          6.7555e-01,  1.3215e-01,  2.8301e+00,  4.6321e-01],\n",
      "        [-1.9149e+00, -1.5384e+00, -6.5300e-01,  1.6415e-01,  2.4937e+00,\n",
      "          1.0387e+00, -3.9085e-01,  1.0208e+00, -1.2269e+00],\n",
      "        [-2.0580e+00,  5.9877e-01, -1.3596e-01,  7.5284e-01, -4.7011e-01,\n",
      "         -9.5008e-01, -6.8084e-01, -9.8090e-01, -7.5196e-01],\n",
      "        [-1.0205e+00, -1.8080e+00,  8.2228e-01,  6.9705e-01,  4.5832e-01,\n",
      "         -1.9562e+00,  1.3033e+00, -1.6942e+00, -1.2161e+00],\n",
      "        [-1.6465e+00, -5.3339e-01, -1.3139e+00,  1.2118e+00,  9.3320e-01,\n",
      "         -2.6052e-01,  1.5152e+00, -1.5212e+00, -1.1670e+00],\n",
      "        [-1.2340e-02, -8.2605e-02,  1.4357e+00,  1.4097e-01, -2.1381e-01,\n",
      "         -9.8981e-01,  3.6573e-01,  1.9153e+00, -1.5250e+00],\n",
      "        [ 3.4487e-01, -1.2002e+00, -1.9729e-01, -2.0704e-01, -6.7425e-01,\n",
      "          4.6213e-01, -8.8553e-01,  1.1178e-01,  7.3621e-01],\n",
      "        [ 9.1191e-01, -3.8249e-01,  1.9816e-01, -2.9362e-02, -9.2658e-01,\n",
      "          1.1700e+00, -1.6676e+00, -2.1456e+00,  1.2072e+00],\n",
      "        [-3.3008e-01, -5.1569e-01,  2.2917e-02, -6.7462e-01,  1.3093e+00,\n",
      "         -7.8042e-01,  3.2850e-01, -8.4913e-01,  9.7480e-01],\n",
      "        [-3.7322e-01,  6.0909e-01, -7.5899e-01, -6.4924e-01, -1.5364e+00,\n",
      "          1.1697e+00, -5.5797e-01,  3.8681e-01, -4.9108e-01],\n",
      "        [-3.4043e-01,  1.3093e-01,  6.0867e-01,  7.9241e-01,  3.7320e-01,\n",
      "          6.6949e-01, -2.1174e-01, -3.2395e-01,  2.0990e-01],\n",
      "        [-1.9622e+00, -5.4705e-01, -6.7545e-01,  5.2596e-01,  1.2341e+00,\n",
      "          1.9076e-01, -1.9311e-01,  1.5767e+00,  1.1904e-01],\n",
      "        [ 3.0878e-01,  7.0220e-01, -2.8203e-02,  1.2828e-01,  3.9796e-01,\n",
      "          5.4788e-01, -1.3334e+00, -4.0718e-01, -6.6974e-01],\n",
      "        [-1.4830e+00,  9.0163e-01, -1.3840e+00, -8.0773e-01,  1.2065e+00,\n",
      "          1.8940e-01, -6.5328e-01, -2.3592e-01, -8.9447e-01],\n",
      "        [-3.5587e-01,  1.4644e+00, -8.2367e-01, -3.5769e-01, -9.3807e-01,\n",
      "          1.4365e+00,  1.5855e+00, -6.2026e-01, -3.8291e-01],\n",
      "        [ 8.2953e-01,  1.8437e+00,  3.0293e-02,  2.9346e-01,  4.1116e-01,\n",
      "          2.4587e+00, -2.2767e-01,  1.1029e+00,  9.2210e-01],\n",
      "        [-2.2031e-01, -1.4987e+00,  6.5455e-01,  1.9341e-01, -1.0508e+00,\n",
      "         -1.0594e+00,  1.0216e+00,  4.0450e-01,  1.6023e+00],\n",
      "        [ 4.5534e-01,  5.4991e-01,  2.3298e-01, -8.4797e-03,  6.6167e-02,\n",
      "         -3.0521e-01, -1.0636e-01,  8.0280e-01, -3.9384e-01],\n",
      "        [ 1.5542e+00,  4.9644e-02, -3.3126e-01, -1.9410e-01,  1.0857e+00,\n",
      "         -2.5671e-01, -2.2588e+00,  1.4869e-01, -1.6375e+00],\n",
      "        [-1.3172e-02,  1.2098e+00, -8.4646e-01,  1.3537e+00, -1.3243e+00,\n",
      "          1.6407e+00, -3.4735e-01,  1.3289e-01, -9.0698e-01],\n",
      "        [-1.5480e-01,  1.7390e+00, -9.8814e-02, -1.8139e+00, -6.9336e-01,\n",
      "          1.3771e+00,  1.0370e+00,  5.2205e-01, -2.0087e+00],\n",
      "        [ 2.3084e-01,  7.2425e-02, -1.9682e+00, -1.7817e-01, -1.0025e-01,\n",
      "         -1.5021e+00,  8.9835e-01, -6.1843e-01, -1.8416e+00]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0079,  0.0000, -0.0287, -0.0154,  0.0120,  0.0137,  0.0102, -0.0113,\n",
      "         0.0133,  0.0000, -0.0318,  0.0000, -0.0117,  0.0114,  0.0000,  0.0032,\n",
      "        -0.0034,  0.0091,  0.0283, -0.0101,  0.0000, -0.0102, -0.0213,  0.0000,\n",
      "         0.0012, -0.0112,  0.0000,  0.0092,  0.0000, -0.0102,  0.0103, -0.0020],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.3314,  1.3488,  1.2159,  ...,  1.1791,  1.2723,  2.3211],\n",
      "        [-1.0970, -0.5517, -0.3263,  ...,  0.9571, -1.0222, -1.2121],\n",
      "        [-0.1125,  1.4894, -0.3584,  ...,  0.9921, -0.8279,  1.0575],\n",
      "        ...,\n",
      "        [ 1.8635,  1.2815,  0.4994,  ..., -0.6912, -0.2288,  0.1015],\n",
      "        [-1.1127, -0.4031,  0.2934,  ...,  1.7087,  0.8135, -0.2957],\n",
      "        [ 1.5156, -0.4924, -1.4516,  ...,  0.8985,  0.1122,  0.0556]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0108, -0.0111, -0.0109,  0.0000, -0.0109,  0.0000, -0.0187,  0.0000,\n",
      "         0.0108, -0.0110, -0.0117,  0.0215,  0.0000,  0.0000, -0.0002,  0.0000,\n",
      "         0.0000,  0.0107,  0.0000, -0.0069,  0.0000, -0.0111,  0.0000, -0.0113,\n",
      "         0.0108,  0.0000,  0.0163,  0.0107,  0.0042,  0.0000,  0.0000,  0.0108],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.2015,  1.0550, -0.0140,  ..., -1.5813,  1.9960, -0.6848],\n",
      "        [-0.8599, -0.7761,  0.6829,  ..., -0.5039, -0.9406, -0.3248],\n",
      "        [ 0.4486, -1.4208,  0.2193,  ...,  0.2452,  0.7986,  0.4548],\n",
      "        ...,\n",
      "        [ 0.2393,  0.9545,  0.1634,  ..., -1.6068,  1.4668, -0.9157],\n",
      "        [-1.6389,  0.9854,  0.0113,  ..., -0.1159,  0.2206, -1.7211],\n",
      "        [ 0.0550, -0.1287, -0.2914,  ...,  0.9080, -0.2270, -1.0181]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.2265,  0.3301,  0.2012, -0.1672,  0.1131, -0.0066, -0.2541, -0.2215,\n",
      "         -0.0749,  0.2796, -0.0803, -0.1398, -0.1431, -0.0314, -0.1273,  0.2943,\n",
      "          0.2004,  0.0245,  0.1973,  0.0253,  0.1172,  0.0274, -0.1494, -0.1072,\n",
      "         -0.1357,  0.2564, -0.0133, -0.1206, -0.0506,  0.0326,  0.0047, -0.1622,\n",
      "         -0.2598,  0.1184,  0.2158,  0.3372,  0.2564, -0.1649,  0.2866, -0.0550,\n",
      "         -0.2062, -0.1262,  0.1612,  0.1379,  0.1619, -0.2378, -0.0729,  0.0161,\n",
      "          0.0681, -0.1784,  0.0434,  0.2375,  0.0898,  0.0227,  0.0743,  0.1377,\n",
      "         -0.1412, -0.1283, -0.1035,  0.0130,  0.0592, -0.0983, -0.0585, -0.0856]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0109], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "test_loading = GCN_BASE_model(data_num_features=data.num_features, embedding_size=32).to(device)\n",
    "test_loading.load_state_dict(torch.load(\"Debug/first_model_e5.pth\"))\n",
    "for i in test_loading.parameters():\n",
    "    print(i)\n",
    "# for param_tensor in test_loading.state_dict():\n",
    "    # print(param_tensor, \"\\t\", test_loading.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer's state_dict:\n",
      "state \t {0: {'step': tensor(250.), 'exp_avg': tensor([ 0.3994, -1.5455,  0.0000,  1.8998, -0.3678,  0.0000,  0.0000, -0.5411,\n",
      "         0.0000,  0.4349,  0.5033,  0.0000,  0.0000,  5.7753,  0.0000,  1.4242,\n",
      "        -0.4399,  1.2948,  0.0000,  0.0000, -0.4933,  0.0000, -0.3783,  0.0000,\n",
      "         0.0000,  0.2415, -0.4265, -0.7635, -2.0682,  0.5678,  0.0000,  3.3379]), 'exp_avg_sq': tensor([3.3387e+02, 1.0446e+04, 0.0000e+00, 6.7252e+02, 1.2933e+01, 0.0000e+00,\n",
      "        0.0000e+00, 9.2839e+02, 0.0000e+00, 7.1529e+03, 3.6696e+02, 0.0000e+00,\n",
      "        0.0000e+00, 4.0669e+03, 0.0000e+00, 1.4374e+02, 6.2673e-01, 2.4534e+01,\n",
      "        0.0000e+00, 0.0000e+00, 2.9381e+03, 0.0000e+00, 6.4072e+00, 0.0000e+00,\n",
      "        0.0000e+00, 2.3226e+02, 1.5215e+03, 1.4339e+03, 3.8165e+01, 8.4634e+02,\n",
      "        0.0000e+00, 8.6629e+01])}, 1: {'step': tensor(250.), 'exp_avg': tensor([[ 1.7100e+00,  0.0000e+00,  4.3469e+00,  1.7947e+00,  1.9313e-01,\n",
      "          0.0000e+00,  2.8990e+00, -8.1811e-01,  4.6953e+00],\n",
      "        [-5.6631e+00,  0.0000e+00, -1.1112e+01, -7.8600e+00,  7.7531e+00,\n",
      "          0.0000e+00, -7.7455e+00,  2.5900e+00, -2.1693e+01],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.1689e+01,  0.0000e+00,  6.2517e+00,  9.3031e+00, -4.5049e-01,\n",
      "          0.0000e+00,  8.0144e+00, -2.6020e-01,  5.5299e+00],\n",
      "        [-7.1346e+00,  0.0000e+00, -4.0654e+00, -1.6893e+00, -1.4660e+00,\n",
      "          0.0000e+00, -1.9485e+00, -4.1649e-01, -3.0097e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.7907e+01,  0.0000e+00,  2.2549e+00, -2.7092e+00, -4.5264e+00,\n",
      "          0.0000e+00, -6.9320e-01, -1.2353e+00,  1.0431e+01],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.5724e+01,  0.0000e+00, -1.2277e-01,  2.2705e+00,  1.0909e+01,\n",
      "          0.0000e+00,  3.1304e+00,  6.5213e-01, -1.8201e+01],\n",
      "        [ 7.4727e+00,  0.0000e+00,  2.1654e+00,  2.6786e+00, -3.2439e+00,\n",
      "          0.0000e+00,  2.3680e+00, -6.9703e-01,  6.0440e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 2.8234e+01,  0.0000e+00,  2.2252e+01,  2.8408e+01, -5.4649e+00,\n",
      "          0.0000e+00,  2.5391e+01, -3.3992e+00,  2.1827e+01],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.3980e+01,  0.0000e+00,  5.9811e+00,  7.2162e+00,  4.1019e+00,\n",
      "          0.0000e+00,  6.8489e+00, -8.0542e-01, -2.3254e+00],\n",
      "        [-1.2840e+01,  0.0000e+00, -9.5337e-01, -2.3053e+00, -1.9129e-01,\n",
      "          0.0000e+00, -1.7461e+00, -1.5841e-01, -1.6836e-01],\n",
      "        [ 3.6272e+00,  0.0000e+00,  3.9783e+00,  6.6485e+00,  2.9501e-01,\n",
      "          0.0000e+00,  4.1544e+00,  1.4044e-01,  1.6835e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2340e+01,  0.0000e+00, -5.0195e+00, -2.1365e+00,  4.2803e+00,\n",
      "          0.0000e+00, -4.2174e+00,  2.4902e+00, -1.0522e+01],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-2.0424e+01,  0.0000e+00, -1.0789e+00, -1.8876e+00,  5.9089e-02,\n",
      "          0.0000e+00, -1.4283e+00, -7.8236e-01, -7.9213e-01],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0248e+01,  0.0000e+00,  9.5623e-01,  9.9060e-01,  3.2705e+00,\n",
      "          0.0000e+00,  5.5529e-01,  2.6308e-01, -2.8358e+00],\n",
      "        [-1.7324e+01,  0.0000e+00,  6.7070e-01, -2.1549e+00, -4.8715e+00,\n",
      "          0.0000e+00, -2.0048e+00, -3.0263e-01,  9.9694e+00],\n",
      "        [-6.8898e+00,  0.0000e+00, -3.2305e+00, -3.8962e+00, -6.0176e+00,\n",
      "          0.0000e+00, -3.6161e+00, -3.3408e-01,  6.8212e+00],\n",
      "        [-1.8523e+00,  0.0000e+00, -5.7700e+00, -1.0795e+01, -2.2262e+00,\n",
      "          0.0000e+00, -8.1246e+00,  6.1809e-01,  1.2547e+00],\n",
      "        [ 1.9661e+00,  0.0000e+00,  1.6933e+00,  2.9183e+00,  4.2067e+00,\n",
      "          0.0000e+00,  2.5698e+00, -2.2101e-02, -5.3397e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 2.6762e+01,  0.0000e+00,  6.9766e+00,  1.6195e+01,  1.5094e+00,\n",
      "          0.0000e+00,  1.2595e+01, -2.8792e-01, -2.7306e-01]]), 'exp_avg_sq': tensor([[2.0962e+04, 0.0000e+00, 3.2108e+03, 8.5075e+03, 4.1796e+02, 0.0000e+00,\n",
      "         4.4494e+03, 1.5317e+01, 5.8705e+01],\n",
      "        [5.7714e+05, 0.0000e+00, 9.5303e+04, 2.6213e+05, 9.7540e+03, 0.0000e+00,\n",
      "         1.2338e+05, 1.5354e+03, 2.8788e+03],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [2.7547e+04, 0.0000e+00, 6.7303e+03, 1.6876e+04, 8.0285e+02, 0.0000e+00,\n",
      "         7.8405e+03, 1.1331e+02, 2.4129e+02],\n",
      "        [3.8608e+03, 0.0000e+00, 1.4862e+02, 3.3442e+02, 5.8981e+01, 0.0000e+00,\n",
      "         1.9864e+02, 4.9401e+00, 8.4263e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [5.0093e+04, 0.0000e+00, 8.1262e+03, 2.3269e+04, 7.6257e+02, 0.0000e+00,\n",
      "         1.0832e+04, 1.2969e+02, 2.9435e+02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [3.9675e+05, 0.0000e+00, 5.7538e+04, 1.7875e+05, 3.5459e+03, 0.0000e+00,\n",
      "         7.7355e+04, 1.8528e+03, 3.0404e+03],\n",
      "        [2.3789e+04, 0.0000e+00, 2.9787e+03, 9.1218e+03, 2.1746e+02, 0.0000e+00,\n",
      "         4.0597e+03, 7.2434e+01, 1.5612e+02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.6951e+05, 0.0000e+00, 4.0696e+04, 1.0191e+05, 4.9510e+03, 0.0000e+00,\n",
      "         4.7940e+04, 4.7509e+02, 1.1859e+03],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [7.2295e+03, 0.0000e+00, 1.1385e+03, 3.4750e+03, 7.6437e+01, 0.0000e+00,\n",
      "         1.4826e+03, 4.3053e+01, 9.2313e+01],\n",
      "        [3.6824e+02, 0.0000e+00, 2.9994e+00, 1.6536e+01, 1.8662e-01, 0.0000e+00,\n",
      "         8.4137e+00, 1.4676e-01, 1.4840e-01],\n",
      "        [1.7608e+03, 0.0000e+00, 1.5013e+02, 6.2785e+02, 1.6576e+00, 0.0000e+00,\n",
      "         2.7069e+02, 3.0410e+00, 8.3559e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.4110e+05, 0.0000e+00, 2.9226e+04, 7.3765e+04, 3.8644e+03, 0.0000e+00,\n",
      "         3.5952e+04, 3.3447e+02, 6.0181e+02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [4.1711e+03, 0.0000e+00, 3.3621e+01, 1.6398e+02, 5.1394e+00, 0.0000e+00,\n",
      "         9.9198e+01, 3.4500e-01, 3.4795e-01],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [2.0136e+04, 0.0000e+00, 2.0534e+03, 5.8671e+03, 2.2739e+02, 0.0000e+00,\n",
      "         2.6873e+03, 6.3076e+01, 6.5581e+01],\n",
      "        [8.4097e+04, 0.0000e+00, 1.2752e+04, 3.8071e+04, 9.9330e+02, 0.0000e+00,\n",
      "         1.7280e+04, 2.6548e+02, 5.8444e+02],\n",
      "        [7.4049e+04, 0.0000e+00, 1.2966e+04, 3.5643e+04, 1.2924e+03, 0.0000e+00,\n",
      "         1.6005e+04, 3.1164e+02, 5.1713e+02],\n",
      "        [1.2717e+04, 0.0000e+00, 1.9651e+02, 9.9891e+02, 2.1690e+01, 0.0000e+00,\n",
      "         5.4813e+02, 2.1727e+00, 2.4279e+00],\n",
      "        [6.1929e+04, 0.0000e+00, 6.6331e+03, 2.1106e+04, 4.2166e+02, 0.0000e+00,\n",
      "         9.1490e+03, 1.8949e+02, 3.1268e+02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [2.7815e+04, 0.0000e+00, 3.6128e+02, 2.0132e+03, 2.5786e+01, 0.0000e+00,\n",
      "         1.1817e+03, 2.1213e+00, 2.3914e+00]])}, 2: {'step': tensor(250.), 'exp_avg': tensor([ 0.0883,  0.0000,  0.0067,  0.1294,  0.1828,  0.0072, -0.7224, -0.1306,\n",
      "         0.0719,  0.0000, -0.1403,  0.0000, -0.1264,  0.2161,  0.0000,  0.8449,\n",
      "         0.3089,  0.1297,  0.0184,  0.0152,  0.0000, -0.2178,  0.3896,  0.0000,\n",
      "        -0.4621,  0.5254,  0.0000, -0.1880,  0.0000,  0.2391,  0.1348,  0.1567]), 'exp_avg_sq': tensor([2.5099e+01, 0.0000e+00, 2.7050e+01, 4.1762e-01, 3.2505e+02, 3.8966e+01,\n",
      "        2.8514e+02, 6.3652e+01, 6.9144e+00, 0.0000e+00, 2.4640e-01, 0.0000e+00,\n",
      "        4.2706e+02, 1.3485e+02, 0.0000e+00, 8.4752e+00, 1.0611e+01, 8.2180e+01,\n",
      "        4.3073e+00, 8.2547e+01, 0.0000e+00, 8.6216e+01, 3.7510e+00, 0.0000e+00,\n",
      "        9.5871e-01, 1.3155e+02, 0.0000e+00, 2.0332e+01, 0.0000e+00, 1.5345e+02,\n",
      "        3.1142e+01, 8.3852e-01])}, 3: {'step': tensor(250.), 'exp_avg': tensor([[ 1.8922e+00,  3.9037e+00,  0.0000e+00,  ..., -1.6428e+00,\n",
      "          0.0000e+00,  1.0904e-01],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 3.5161e-02,  9.1715e-02,  0.0000e+00,  ...,  2.7323e-05,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        ...,\n",
      "        [ 3.2332e+00,  7.9603e+00,  0.0000e+00,  ...,  2.1914e+00,\n",
      "          0.0000e+00,  3.3647e-01],\n",
      "        [ 1.9123e+00,  2.7783e+00,  0.0000e+00,  ..., -1.5901e+00,\n",
      "          0.0000e+00,  9.7603e-02],\n",
      "        [ 3.4795e-01,  1.1426e+00,  0.0000e+00,  ...,  6.0255e-01,\n",
      "          0.0000e+00,  1.2535e-01]]), 'exp_avg_sq': tensor([[8.7300e+02, 2.9986e+03, 0.0000e+00,  ..., 4.0430e+01, 0.0000e+00,\n",
      "         2.5727e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [6.6607e+02, 4.4865e+03, 0.0000e+00,  ..., 7.2659e-01, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        ...,\n",
      "        [5.5925e+03, 1.5514e+04, 0.0000e+00,  ..., 4.5761e+02, 0.0000e+00,\n",
      "         1.6815e+01],\n",
      "        [1.1229e+03, 3.3988e+03, 0.0000e+00,  ..., 7.6780e+01, 0.0000e+00,\n",
      "         2.5251e+00],\n",
      "        [3.0658e+02, 2.1838e+02, 0.0000e+00,  ..., 5.2326e+00, 0.0000e+00,\n",
      "         7.3524e+00]])}, 4: {'step': tensor(250.), 'exp_avg': tensor([-6.6938e-02, -1.5268e-01,  5.7927e-02,  0.0000e+00,  5.1290e-02,\n",
      "         0.0000e+00,  5.4664e-03,  0.0000e+00, -3.8667e-02,  2.1747e-02,\n",
      "         2.3018e-11, -3.6002e-02,  0.0000e+00,  0.0000e+00, -3.0325e-02,\n",
      "         0.0000e+00,  0.0000e+00, -2.1031e-02,  0.0000e+00,  9.3671e-02,\n",
      "         0.0000e+00,  6.1015e-03,  0.0000e+00,  4.0755e-03, -3.8284e-02,\n",
      "         0.0000e+00,  6.0024e-02, -1.5625e-02, -1.8757e-03,  0.0000e+00,\n",
      "         0.0000e+00, -3.4934e-02]), 'exp_avg_sq': tensor([1.9058e+01, 1.4459e+01, 1.4861e+01, 0.0000e+00, 1.1746e+01, 0.0000e+00,\n",
      "        2.7361e-01, 0.0000e+00, 6.3182e+00, 2.1150e+00, 2.7319e-03, 5.6450e-02,\n",
      "        0.0000e+00, 0.0000e+00, 7.1051e-01, 0.0000e+00, 0.0000e+00, 1.8296e+00,\n",
      "        0.0000e+00, 3.7702e-01, 0.0000e+00, 3.9547e-01, 0.0000e+00, 1.4709e-01,\n",
      "        5.7680e+00, 0.0000e+00, 2.9451e-02, 6.5834e-01, 6.7674e-03, 0.0000e+00,\n",
      "        0.0000e+00, 4.4783e+00])}, 5: {'step': tensor(250.), 'exp_avg': tensor([[-2.1658e+01,  0.0000e+00, -2.9485e-04,  ..., -8.3946e+00,\n",
      "          1.7659e-02,  2.2029e+00],\n",
      "        [ 7.5140e+00,  0.0000e+00,  3.5453e-04,  ..., -1.0179e+01,\n",
      "         -8.8733e+00,  5.8965e-14],\n",
      "        [ 1.7379e+01,  0.0000e+00,  2.3230e-04,  ...,  7.6976e+00,\n",
      "         -1.6118e-01, -1.8705e+00],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-8.4840e+00,  0.0000e+00, -1.3238e-04,  ..., -1.5285e+00,\n",
      "         -2.5928e-01,  1.3420e+00]]), 'exp_avg_sq': tensor([[1.0869e+04, 0.0000e+00, 6.8109e+00,  ..., 4.5562e+04, 2.7912e+04,\n",
      "         1.1224e+02],\n",
      "        [6.0248e+03, 0.0000e+00, 3.6040e+01,  ..., 2.7339e+04, 1.6036e+04,\n",
      "         1.0916e-05],\n",
      "        [8.7899e+03, 0.0000e+00, 5.2247e+00,  ..., 3.6085e+04, 2.1924e+04,\n",
      "         7.9703e+01],\n",
      "        ...,\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [3.1146e+03, 0.0000e+00, 2.3633e+00,  ..., 1.2473e+04, 7.0157e+03,\n",
      "         3.1719e+01]])}, 6: {'step': tensor(250.), 'exp_avg': tensor([[-1.5762e+02, -1.7854e+01,  2.1367e+01,  0.0000e+00,  3.7763e-01,\n",
      "          0.0000e+00,  2.6600e+01,  0.0000e+00, -7.8873e+01, -7.5609e+01,\n",
      "          4.7515e-10, -1.2778e+01,  0.0000e+00,  0.0000e+00,  2.1798e-01,\n",
      "          0.0000e+00,  0.0000e+00, -6.6960e+01,  0.0000e+00, -3.7956e+01,\n",
      "          0.0000e+00,  7.3504e+01,  0.0000e+00,  1.0954e+01, -9.4607e+01,\n",
      "          0.0000e+00, -2.1074e+00,  3.7155e+01,  6.5905e+00,  0.0000e+00,\n",
      "          0.0000e+00,  1.0556e+01, -6.3396e+01, -7.2575e+00,  5.0181e+01,\n",
      "          0.0000e+00,  1.3231e+02,  0.0000e+00,  5.9051e+01,  0.0000e+00,\n",
      "         -1.7010e+01, -1.3678e+01,  3.0402e-10,  7.4777e+00,  0.0000e+00,\n",
      "          0.0000e+00,  2.1182e+00,  0.0000e+00,  0.0000e+00, -3.6247e+00,\n",
      "          0.0000e+00, -1.8661e+00,  0.0000e+00,  9.7956e+01,  0.0000e+00,\n",
      "          6.5101e+01,  4.3646e+00,  0.0000e+00,  7.3775e+00,  9.7279e+01,\n",
      "          1.7372e+01,  0.0000e+00,  0.0000e+00,  6.1052e+01]]), 'exp_avg_sq': tensor([[3.8883e+06, 1.8730e+04, 2.7861e+06, 0.0000e+00, 1.4863e+07, 0.0000e+00,\n",
      "         1.6205e+05, 0.0000e+00, 1.8372e+06, 2.7238e+06, 2.3667e+02, 5.0122e+04,\n",
      "         0.0000e+00, 0.0000e+00, 1.0101e+03, 0.0000e+00, 0.0000e+00, 1.4619e+06,\n",
      "         0.0000e+00, 4.5779e+04, 0.0000e+00, 1.5665e+06, 0.0000e+00, 6.2313e+06,\n",
      "         1.2104e+06, 0.0000e+00, 1.7869e+03, 1.8595e+06, 2.9036e+04, 0.0000e+00,\n",
      "         0.0000e+00, 2.0423e+06, 2.2074e+06, 6.7222e+03, 1.6543e+06, 0.0000e+00,\n",
      "         9.1320e+06, 0.0000e+00, 8.4719e+04, 0.0000e+00, 9.7440e+05, 1.7099e+06,\n",
      "         4.4140e+01, 2.2668e+04, 0.0000e+00, 0.0000e+00, 1.9740e+02, 0.0000e+00,\n",
      "         0.0000e+00, 8.2416e+05, 0.0000e+00, 1.4026e+04, 0.0000e+00, 9.5274e+05,\n",
      "         0.0000e+00, 3.7977e+06, 7.3986e+05, 0.0000e+00, 5.3481e+02, 1.2162e+06,\n",
      "         1.3722e+04, 0.0000e+00, 0.0000e+00, 1.1992e+06]])}, 7: {'step': tensor(250.), 'exp_avg': tensor([0.1394]), 'exp_avg_sq': tensor([80.9953])}}\n",
      "param_groups \t [{'lr': 0.0007, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'maximize': False, 'foreach': None, 'capturable': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7]}]\n"
     ]
    }
   ],
   "source": [
    "# Print optimizer's state_dict\n",
    "test_op  = torch.optim.Adam(test_loading.parameters(), lr=0.0007)\n",
    "test_op.load_state_dict(torch.load(\"Debug/first_modeloptimizer_e5.pth\"))\n",
    "\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([ 0.0126, -0.0116,  0.0000,  0.0095,  0.0170,  0.0000,  0.0000,  0.0122,\n",
      "         0.0000, -0.0073,  0.0087,  0.0000,  0.0000,  0.0112,  0.0000, -0.0126,\n",
      "         0.0303,  0.0030,  0.0000,  0.0000, -0.0145,  0.0000,  0.0167,  0.0000,\n",
      "         0.0000,  0.0056,  0.0112,  0.0112,  0.0036, -0.0076,  0.0000, -0.0100],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 9.9713e-01,  1.3733e+00, -3.1562e-01, -5.2806e-01,  5.4191e-01,\n",
      "         -1.1346e+00,  4.8438e-01, -7.0008e-01,  4.5105e-01],\n",
      "        [ 5.5859e-01,  2.4628e-01,  2.8755e+00, -5.6728e-01, -4.6676e-03,\n",
      "         -3.9583e-01,  3.9306e-01,  1.5500e-01, -2.7219e+00],\n",
      "        [-1.2835e-01, -4.4340e-01, -1.7999e+00, -4.8732e-01, -3.6020e-01,\n",
      "         -8.5379e-01,  1.3559e+00, -6.2743e-01,  4.7283e-01],\n",
      "        [-6.7590e-01,  1.4168e+00,  8.6890e-01,  8.9256e-01, -8.8550e-01,\n",
      "         -1.3402e+00,  4.4579e-02, -4.4704e-01,  1.3631e-01],\n",
      "        [ 1.6322e+00, -4.2968e-01, -1.2002e-01,  3.1908e-01, -9.5652e-01,\n",
      "          2.9410e-01, -3.3934e-01, -1.3381e-01, -7.2239e-02],\n",
      "        [-1.9935e+00,  1.1608e-01,  1.3771e+00,  8.5450e-01, -1.1794e+00,\n",
      "         -9.5405e-01, -9.6967e-01,  3.1414e-01,  1.2000e+00],\n",
      "        [-1.8317e-01,  4.2561e-01, -1.0347e-01, -1.0870e-01,  5.7822e-01,\n",
      "          1.7500e+00,  2.0350e-03,  3.6501e-01, -8.9467e-01],\n",
      "        [ 1.1870e+00,  1.1797e+00,  8.3901e-01,  1.4699e+00, -1.0065e+00,\n",
      "         -1.2957e+00,  2.9701e-01, -2.1987e+00,  8.3223e-01],\n",
      "        [-1.2931e+00,  4.5108e-01, -3.9537e-01,  1.7162e+00,  1.5393e-01,\n",
      "         -1.4652e+00, -5.1707e-01, -3.5225e-01, -8.1010e-01],\n",
      "        [ 6.7270e-01,  3.3716e-01, -5.3640e-01,  9.2520e-01,  6.6032e-01,\n",
      "          1.4379e-01, -5.4495e-01,  3.5628e-02,  2.2501e-01],\n",
      "        [ 2.3985e+00,  4.0238e-01,  1.6965e+00, -2.7353e+00, -1.8834e+00,\n",
      "          6.7555e-01,  1.3215e-01,  2.8301e+00,  4.6321e-01],\n",
      "        [-1.9149e+00, -1.5384e+00, -6.5300e-01,  1.6415e-01,  2.4937e+00,\n",
      "          1.0387e+00, -3.9085e-01,  1.0208e+00, -1.2269e+00],\n",
      "        [-2.0580e+00,  5.9877e-01, -1.3596e-01,  7.5284e-01, -4.7011e-01,\n",
      "         -9.5008e-01, -6.8084e-01, -9.8090e-01, -7.5196e-01],\n",
      "        [-1.0205e+00, -1.8080e+00,  8.2228e-01,  6.9705e-01,  4.5832e-01,\n",
      "         -1.9562e+00,  1.3033e+00, -1.6942e+00, -1.2161e+00],\n",
      "        [-1.6465e+00, -5.3339e-01, -1.3139e+00,  1.2118e+00,  9.3320e-01,\n",
      "         -2.6052e-01,  1.5152e+00, -1.5212e+00, -1.1670e+00],\n",
      "        [-1.2340e-02, -8.2605e-02,  1.4357e+00,  1.4097e-01, -2.1381e-01,\n",
      "         -9.8981e-01,  3.6573e-01,  1.9153e+00, -1.5250e+00],\n",
      "        [ 3.4487e-01, -1.2002e+00, -1.9729e-01, -2.0704e-01, -6.7425e-01,\n",
      "          4.6213e-01, -8.8553e-01,  1.1178e-01,  7.3621e-01],\n",
      "        [ 9.1191e-01, -3.8249e-01,  1.9816e-01, -2.9362e-02, -9.2658e-01,\n",
      "          1.1700e+00, -1.6676e+00, -2.1456e+00,  1.2072e+00],\n",
      "        [-3.3008e-01, -5.1569e-01,  2.2917e-02, -6.7462e-01,  1.3093e+00,\n",
      "         -7.8042e-01,  3.2850e-01, -8.4913e-01,  9.7480e-01],\n",
      "        [-3.7322e-01,  6.0909e-01, -7.5899e-01, -6.4924e-01, -1.5364e+00,\n",
      "          1.1697e+00, -5.5797e-01,  3.8681e-01, -4.9108e-01],\n",
      "        [-3.4043e-01,  1.3093e-01,  6.0867e-01,  7.9241e-01,  3.7320e-01,\n",
      "          6.6949e-01, -2.1174e-01, -3.2395e-01,  2.0990e-01],\n",
      "        [-1.9622e+00, -5.4705e-01, -6.7545e-01,  5.2596e-01,  1.2341e+00,\n",
      "          1.9076e-01, -1.9311e-01,  1.5767e+00,  1.1904e-01],\n",
      "        [ 3.0878e-01,  7.0220e-01, -2.8203e-02,  1.2828e-01,  3.9796e-01,\n",
      "          5.4788e-01, -1.3334e+00, -4.0718e-01, -6.6974e-01],\n",
      "        [-1.4830e+00,  9.0163e-01, -1.3840e+00, -8.0773e-01,  1.2065e+00,\n",
      "          1.8940e-01, -6.5328e-01, -2.3592e-01, -8.9447e-01],\n",
      "        [-3.5587e-01,  1.4644e+00, -8.2367e-01, -3.5769e-01, -9.3807e-01,\n",
      "          1.4365e+00,  1.5855e+00, -6.2026e-01, -3.8291e-01],\n",
      "        [ 8.2953e-01,  1.8437e+00,  3.0293e-02,  2.9346e-01,  4.1116e-01,\n",
      "          2.4587e+00, -2.2767e-01,  1.1029e+00,  9.2210e-01],\n",
      "        [-2.2031e-01, -1.4987e+00,  6.5455e-01,  1.9341e-01, -1.0508e+00,\n",
      "         -1.0594e+00,  1.0216e+00,  4.0450e-01,  1.6023e+00],\n",
      "        [ 4.5534e-01,  5.4991e-01,  2.3298e-01, -8.4797e-03,  6.6167e-02,\n",
      "         -3.0521e-01, -1.0636e-01,  8.0280e-01, -3.9384e-01],\n",
      "        [ 1.5542e+00,  4.9644e-02, -3.3126e-01, -1.9410e-01,  1.0857e+00,\n",
      "         -2.5671e-01, -2.2588e+00,  1.4869e-01, -1.6375e+00],\n",
      "        [-1.3172e-02,  1.2098e+00, -8.4646e-01,  1.3537e+00, -1.3243e+00,\n",
      "          1.6407e+00, -3.4735e-01,  1.3289e-01, -9.0698e-01],\n",
      "        [-1.5480e-01,  1.7390e+00, -9.8814e-02, -1.8139e+00, -6.9336e-01,\n",
      "          1.3771e+00,  1.0370e+00,  5.2205e-01, -2.0087e+00],\n",
      "        [ 2.3084e-01,  7.2425e-02, -1.9682e+00, -1.7817e-01, -1.0025e-01,\n",
      "         -1.5021e+00,  8.9835e-01, -6.1843e-01, -1.8416e+00]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0079,  0.0000, -0.0287, -0.0154,  0.0120,  0.0137,  0.0102, -0.0113,\n",
      "         0.0133,  0.0000, -0.0318,  0.0000, -0.0117,  0.0114,  0.0000,  0.0032,\n",
      "        -0.0034,  0.0091,  0.0283, -0.0101,  0.0000, -0.0102, -0.0213,  0.0000,\n",
      "         0.0012, -0.0112,  0.0000,  0.0092,  0.0000, -0.0102,  0.0103, -0.0020],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.3314,  1.3488,  1.2159,  ...,  1.1791,  1.2723,  2.3211],\n",
      "        [-1.0970, -0.5517, -0.3263,  ...,  0.9571, -1.0222, -1.2121],\n",
      "        [-0.1125,  1.4894, -0.3584,  ...,  0.9921, -0.8279,  1.0575],\n",
      "        ...,\n",
      "        [ 1.8635,  1.2815,  0.4994,  ..., -0.6912, -0.2288,  0.1015],\n",
      "        [-1.1127, -0.4031,  0.2934,  ...,  1.7087,  0.8135, -0.2957],\n",
      "        [ 1.5156, -0.4924, -1.4516,  ...,  0.8985,  0.1122,  0.0556]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0108, -0.0111, -0.0109,  0.0000, -0.0109,  0.0000, -0.0187,  0.0000,\n",
      "         0.0108, -0.0110, -0.0117,  0.0215,  0.0000,  0.0000, -0.0002,  0.0000,\n",
      "         0.0000,  0.0107,  0.0000, -0.0069,  0.0000, -0.0111,  0.0000, -0.0113,\n",
      "         0.0108,  0.0000,  0.0163,  0.0107,  0.0042,  0.0000,  0.0000,  0.0108],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.2015,  1.0550, -0.0140,  ..., -1.5813,  1.9960, -0.6848],\n",
      "        [-0.8599, -0.7761,  0.6829,  ..., -0.5039, -0.9406, -0.3248],\n",
      "        [ 0.4486, -1.4208,  0.2193,  ...,  0.2452,  0.7986,  0.4548],\n",
      "        ...,\n",
      "        [ 0.2393,  0.9545,  0.1634,  ..., -1.6068,  1.4668, -0.9157],\n",
      "        [-1.6389,  0.9854,  0.0113,  ..., -0.1159,  0.2206, -1.7211],\n",
      "        [ 0.0550, -0.1287, -0.2914,  ...,  0.9080, -0.2270, -1.0181]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.2265,  0.3301,  0.2012, -0.1672,  0.1131, -0.0066, -0.2541, -0.2215,\n",
      "         -0.0749,  0.2796, -0.0803, -0.1398, -0.1431, -0.0314, -0.1273,  0.2943,\n",
      "          0.2004,  0.0245,  0.1973,  0.0253,  0.1172,  0.0274, -0.1494, -0.1072,\n",
      "         -0.1357,  0.2564, -0.0133, -0.1206, -0.0506,  0.0326,  0.0047, -0.1622,\n",
      "         -0.2598,  0.1184,  0.2158,  0.3372,  0.2564, -0.1649,  0.2866, -0.0550,\n",
      "         -0.2062, -0.1262,  0.1612,  0.1379,  0.1619, -0.2378, -0.0729,  0.0161,\n",
      "          0.0681, -0.1784,  0.0434,  0.2375,  0.0898,  0.0227,  0.0743,  0.1377,\n",
      "         -0.1412, -0.1283, -0.1035,  0.0130,  0.0592, -0.0983, -0.0585, -0.0856]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0109], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for i in first_model.parameters():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "initial_conv.bias \t torch.Size([32])\n",
      "initial_conv.lin.weight \t torch.Size([32, 9])\n",
      "conv1.bias \t torch.Size([32])\n",
      "conv1.lin.weight \t torch.Size([32, 32])\n",
      "conv2.bias \t torch.Size([32])\n",
      "conv2.lin.weight \t torch.Size([32, 32])\n",
      "out.weight \t torch.Size([1, 64])\n",
      "out.bias \t torch.Size([1])\n",
      "Optimizer's state_dict:\n",
      "state \t {0: {'step': tensor(250.), 'exp_avg': tensor([ 0.3994, -1.5455,  0.0000,  1.8998, -0.3678,  0.0000,  0.0000, -0.5411,\n",
      "         0.0000,  0.4349,  0.5033,  0.0000,  0.0000,  5.7753,  0.0000,  1.4242,\n",
      "        -0.4399,  1.2948,  0.0000,  0.0000, -0.4933,  0.0000, -0.3783,  0.0000,\n",
      "         0.0000,  0.2415, -0.4265, -0.7635, -2.0682,  0.5678,  0.0000,  3.3379]), 'exp_avg_sq': tensor([3.3387e+02, 1.0446e+04, 0.0000e+00, 6.7252e+02, 1.2933e+01, 0.0000e+00,\n",
      "        0.0000e+00, 9.2839e+02, 0.0000e+00, 7.1529e+03, 3.6696e+02, 0.0000e+00,\n",
      "        0.0000e+00, 4.0669e+03, 0.0000e+00, 1.4374e+02, 6.2673e-01, 2.4534e+01,\n",
      "        0.0000e+00, 0.0000e+00, 2.9381e+03, 0.0000e+00, 6.4072e+00, 0.0000e+00,\n",
      "        0.0000e+00, 2.3226e+02, 1.5215e+03, 1.4339e+03, 3.8165e+01, 8.4634e+02,\n",
      "        0.0000e+00, 8.6629e+01])}, 1: {'step': tensor(250.), 'exp_avg': tensor([[ 1.7100e+00,  0.0000e+00,  4.3469e+00,  1.7947e+00,  1.9313e-01,\n",
      "          0.0000e+00,  2.8990e+00, -8.1811e-01,  4.6953e+00],\n",
      "        [-5.6631e+00,  0.0000e+00, -1.1112e+01, -7.8600e+00,  7.7531e+00,\n",
      "          0.0000e+00, -7.7455e+00,  2.5900e+00, -2.1693e+01],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.1689e+01,  0.0000e+00,  6.2517e+00,  9.3031e+00, -4.5049e-01,\n",
      "          0.0000e+00,  8.0144e+00, -2.6020e-01,  5.5299e+00],\n",
      "        [-7.1346e+00,  0.0000e+00, -4.0654e+00, -1.6893e+00, -1.4660e+00,\n",
      "          0.0000e+00, -1.9485e+00, -4.1649e-01, -3.0097e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.7907e+01,  0.0000e+00,  2.2549e+00, -2.7092e+00, -4.5264e+00,\n",
      "          0.0000e+00, -6.9320e-01, -1.2353e+00,  1.0431e+01],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.5724e+01,  0.0000e+00, -1.2277e-01,  2.2705e+00,  1.0909e+01,\n",
      "          0.0000e+00,  3.1304e+00,  6.5213e-01, -1.8201e+01],\n",
      "        [ 7.4727e+00,  0.0000e+00,  2.1654e+00,  2.6786e+00, -3.2439e+00,\n",
      "          0.0000e+00,  2.3680e+00, -6.9703e-01,  6.0440e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 2.8234e+01,  0.0000e+00,  2.2252e+01,  2.8408e+01, -5.4649e+00,\n",
      "          0.0000e+00,  2.5391e+01, -3.3992e+00,  2.1827e+01],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.3980e+01,  0.0000e+00,  5.9811e+00,  7.2162e+00,  4.1019e+00,\n",
      "          0.0000e+00,  6.8489e+00, -8.0542e-01, -2.3254e+00],\n",
      "        [-1.2840e+01,  0.0000e+00, -9.5337e-01, -2.3053e+00, -1.9129e-01,\n",
      "          0.0000e+00, -1.7461e+00, -1.5841e-01, -1.6836e-01],\n",
      "        [ 3.6272e+00,  0.0000e+00,  3.9783e+00,  6.6485e+00,  2.9501e-01,\n",
      "          0.0000e+00,  4.1544e+00,  1.4044e-01,  1.6835e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2340e+01,  0.0000e+00, -5.0195e+00, -2.1365e+00,  4.2803e+00,\n",
      "          0.0000e+00, -4.2174e+00,  2.4902e+00, -1.0522e+01],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-2.0424e+01,  0.0000e+00, -1.0789e+00, -1.8876e+00,  5.9089e-02,\n",
      "          0.0000e+00, -1.4283e+00, -7.8236e-01, -7.9213e-01],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0248e+01,  0.0000e+00,  9.5623e-01,  9.9060e-01,  3.2705e+00,\n",
      "          0.0000e+00,  5.5529e-01,  2.6308e-01, -2.8358e+00],\n",
      "        [-1.7324e+01,  0.0000e+00,  6.7070e-01, -2.1549e+00, -4.8715e+00,\n",
      "          0.0000e+00, -2.0048e+00, -3.0263e-01,  9.9694e+00],\n",
      "        [-6.8898e+00,  0.0000e+00, -3.2305e+00, -3.8962e+00, -6.0176e+00,\n",
      "          0.0000e+00, -3.6161e+00, -3.3408e-01,  6.8212e+00],\n",
      "        [-1.8523e+00,  0.0000e+00, -5.7700e+00, -1.0795e+01, -2.2262e+00,\n",
      "          0.0000e+00, -8.1246e+00,  6.1809e-01,  1.2547e+00],\n",
      "        [ 1.9661e+00,  0.0000e+00,  1.6933e+00,  2.9183e+00,  4.2067e+00,\n",
      "          0.0000e+00,  2.5698e+00, -2.2101e-02, -5.3397e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 2.6762e+01,  0.0000e+00,  6.9766e+00,  1.6195e+01,  1.5094e+00,\n",
      "          0.0000e+00,  1.2595e+01, -2.8792e-01, -2.7306e-01]]), 'exp_avg_sq': tensor([[2.0962e+04, 0.0000e+00, 3.2108e+03, 8.5075e+03, 4.1796e+02, 0.0000e+00,\n",
      "         4.4494e+03, 1.5317e+01, 5.8705e+01],\n",
      "        [5.7714e+05, 0.0000e+00, 9.5303e+04, 2.6213e+05, 9.7540e+03, 0.0000e+00,\n",
      "         1.2338e+05, 1.5354e+03, 2.8788e+03],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [2.7547e+04, 0.0000e+00, 6.7303e+03, 1.6876e+04, 8.0285e+02, 0.0000e+00,\n",
      "         7.8405e+03, 1.1331e+02, 2.4129e+02],\n",
      "        [3.8608e+03, 0.0000e+00, 1.4862e+02, 3.3442e+02, 5.8981e+01, 0.0000e+00,\n",
      "         1.9864e+02, 4.9401e+00, 8.4263e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [5.0093e+04, 0.0000e+00, 8.1262e+03, 2.3269e+04, 7.6257e+02, 0.0000e+00,\n",
      "         1.0832e+04, 1.2969e+02, 2.9435e+02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [3.9675e+05, 0.0000e+00, 5.7538e+04, 1.7875e+05, 3.5459e+03, 0.0000e+00,\n",
      "         7.7355e+04, 1.8528e+03, 3.0404e+03],\n",
      "        [2.3789e+04, 0.0000e+00, 2.9787e+03, 9.1218e+03, 2.1746e+02, 0.0000e+00,\n",
      "         4.0597e+03, 7.2434e+01, 1.5612e+02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.6951e+05, 0.0000e+00, 4.0696e+04, 1.0191e+05, 4.9510e+03, 0.0000e+00,\n",
      "         4.7940e+04, 4.7509e+02, 1.1859e+03],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [7.2295e+03, 0.0000e+00, 1.1385e+03, 3.4750e+03, 7.6437e+01, 0.0000e+00,\n",
      "         1.4826e+03, 4.3053e+01, 9.2313e+01],\n",
      "        [3.6824e+02, 0.0000e+00, 2.9994e+00, 1.6536e+01, 1.8662e-01, 0.0000e+00,\n",
      "         8.4137e+00, 1.4676e-01, 1.4840e-01],\n",
      "        [1.7608e+03, 0.0000e+00, 1.5013e+02, 6.2785e+02, 1.6576e+00, 0.0000e+00,\n",
      "         2.7069e+02, 3.0410e+00, 8.3559e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.4110e+05, 0.0000e+00, 2.9226e+04, 7.3765e+04, 3.8644e+03, 0.0000e+00,\n",
      "         3.5952e+04, 3.3447e+02, 6.0181e+02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [4.1711e+03, 0.0000e+00, 3.3621e+01, 1.6398e+02, 5.1394e+00, 0.0000e+00,\n",
      "         9.9198e+01, 3.4500e-01, 3.4795e-01],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [2.0136e+04, 0.0000e+00, 2.0534e+03, 5.8671e+03, 2.2739e+02, 0.0000e+00,\n",
      "         2.6873e+03, 6.3076e+01, 6.5581e+01],\n",
      "        [8.4097e+04, 0.0000e+00, 1.2752e+04, 3.8071e+04, 9.9330e+02, 0.0000e+00,\n",
      "         1.7280e+04, 2.6548e+02, 5.8444e+02],\n",
      "        [7.4049e+04, 0.0000e+00, 1.2966e+04, 3.5643e+04, 1.2924e+03, 0.0000e+00,\n",
      "         1.6005e+04, 3.1164e+02, 5.1713e+02],\n",
      "        [1.2717e+04, 0.0000e+00, 1.9651e+02, 9.9891e+02, 2.1690e+01, 0.0000e+00,\n",
      "         5.4813e+02, 2.1727e+00, 2.4279e+00],\n",
      "        [6.1929e+04, 0.0000e+00, 6.6331e+03, 2.1106e+04, 4.2166e+02, 0.0000e+00,\n",
      "         9.1490e+03, 1.8949e+02, 3.1268e+02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [2.7815e+04, 0.0000e+00, 3.6128e+02, 2.0132e+03, 2.5786e+01, 0.0000e+00,\n",
      "         1.1817e+03, 2.1213e+00, 2.3914e+00]])}, 2: {'step': tensor(250.), 'exp_avg': tensor([ 0.0883,  0.0000,  0.0067,  0.1294,  0.1828,  0.0072, -0.7224, -0.1306,\n",
      "         0.0719,  0.0000, -0.1403,  0.0000, -0.1264,  0.2161,  0.0000,  0.8449,\n",
      "         0.3089,  0.1297,  0.0184,  0.0152,  0.0000, -0.2178,  0.3896,  0.0000,\n",
      "        -0.4621,  0.5254,  0.0000, -0.1880,  0.0000,  0.2391,  0.1348,  0.1567]), 'exp_avg_sq': tensor([2.5099e+01, 0.0000e+00, 2.7050e+01, 4.1762e-01, 3.2505e+02, 3.8966e+01,\n",
      "        2.8514e+02, 6.3652e+01, 6.9144e+00, 0.0000e+00, 2.4640e-01, 0.0000e+00,\n",
      "        4.2706e+02, 1.3485e+02, 0.0000e+00, 8.4752e+00, 1.0611e+01, 8.2180e+01,\n",
      "        4.3073e+00, 8.2547e+01, 0.0000e+00, 8.6216e+01, 3.7510e+00, 0.0000e+00,\n",
      "        9.5871e-01, 1.3155e+02, 0.0000e+00, 2.0332e+01, 0.0000e+00, 1.5345e+02,\n",
      "        3.1142e+01, 8.3852e-01])}, 3: {'step': tensor(250.), 'exp_avg': tensor([[ 1.8922e+00,  3.9037e+00,  0.0000e+00,  ..., -1.6428e+00,\n",
      "          0.0000e+00,  1.0904e-01],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 3.5161e-02,  9.1715e-02,  0.0000e+00,  ...,  2.7323e-05,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        ...,\n",
      "        [ 3.2332e+00,  7.9603e+00,  0.0000e+00,  ...,  2.1914e+00,\n",
      "          0.0000e+00,  3.3647e-01],\n",
      "        [ 1.9123e+00,  2.7783e+00,  0.0000e+00,  ..., -1.5901e+00,\n",
      "          0.0000e+00,  9.7603e-02],\n",
      "        [ 3.4795e-01,  1.1426e+00,  0.0000e+00,  ...,  6.0255e-01,\n",
      "          0.0000e+00,  1.2535e-01]]), 'exp_avg_sq': tensor([[8.7300e+02, 2.9986e+03, 0.0000e+00,  ..., 4.0430e+01, 0.0000e+00,\n",
      "         2.5727e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [6.6607e+02, 4.4865e+03, 0.0000e+00,  ..., 7.2659e-01, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        ...,\n",
      "        [5.5925e+03, 1.5514e+04, 0.0000e+00,  ..., 4.5761e+02, 0.0000e+00,\n",
      "         1.6815e+01],\n",
      "        [1.1229e+03, 3.3988e+03, 0.0000e+00,  ..., 7.6780e+01, 0.0000e+00,\n",
      "         2.5251e+00],\n",
      "        [3.0658e+02, 2.1838e+02, 0.0000e+00,  ..., 5.2326e+00, 0.0000e+00,\n",
      "         7.3524e+00]])}, 4: {'step': tensor(250.), 'exp_avg': tensor([-6.6938e-02, -1.5268e-01,  5.7927e-02,  0.0000e+00,  5.1290e-02,\n",
      "         0.0000e+00,  5.4664e-03,  0.0000e+00, -3.8667e-02,  2.1747e-02,\n",
      "         2.3018e-11, -3.6002e-02,  0.0000e+00,  0.0000e+00, -3.0325e-02,\n",
      "         0.0000e+00,  0.0000e+00, -2.1031e-02,  0.0000e+00,  9.3671e-02,\n",
      "         0.0000e+00,  6.1015e-03,  0.0000e+00,  4.0755e-03, -3.8284e-02,\n",
      "         0.0000e+00,  6.0024e-02, -1.5625e-02, -1.8757e-03,  0.0000e+00,\n",
      "         0.0000e+00, -3.4934e-02]), 'exp_avg_sq': tensor([1.9058e+01, 1.4459e+01, 1.4861e+01, 0.0000e+00, 1.1746e+01, 0.0000e+00,\n",
      "        2.7361e-01, 0.0000e+00, 6.3182e+00, 2.1150e+00, 2.7319e-03, 5.6450e-02,\n",
      "        0.0000e+00, 0.0000e+00, 7.1051e-01, 0.0000e+00, 0.0000e+00, 1.8296e+00,\n",
      "        0.0000e+00, 3.7702e-01, 0.0000e+00, 3.9547e-01, 0.0000e+00, 1.4709e-01,\n",
      "        5.7680e+00, 0.0000e+00, 2.9451e-02, 6.5834e-01, 6.7674e-03, 0.0000e+00,\n",
      "        0.0000e+00, 4.4783e+00])}, 5: {'step': tensor(250.), 'exp_avg': tensor([[-2.1658e+01,  0.0000e+00, -2.9485e-04,  ..., -8.3946e+00,\n",
      "          1.7659e-02,  2.2029e+00],\n",
      "        [ 7.5140e+00,  0.0000e+00,  3.5453e-04,  ..., -1.0179e+01,\n",
      "         -8.8733e+00,  5.8965e-14],\n",
      "        [ 1.7379e+01,  0.0000e+00,  2.3230e-04,  ...,  7.6976e+00,\n",
      "         -1.6118e-01, -1.8705e+00],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-8.4840e+00,  0.0000e+00, -1.3238e-04,  ..., -1.5285e+00,\n",
      "         -2.5928e-01,  1.3420e+00]]), 'exp_avg_sq': tensor([[1.0869e+04, 0.0000e+00, 6.8109e+00,  ..., 4.5562e+04, 2.7912e+04,\n",
      "         1.1224e+02],\n",
      "        [6.0248e+03, 0.0000e+00, 3.6040e+01,  ..., 2.7339e+04, 1.6036e+04,\n",
      "         1.0916e-05],\n",
      "        [8.7899e+03, 0.0000e+00, 5.2247e+00,  ..., 3.6085e+04, 2.1924e+04,\n",
      "         7.9703e+01],\n",
      "        ...,\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [3.1146e+03, 0.0000e+00, 2.3633e+00,  ..., 1.2473e+04, 7.0157e+03,\n",
      "         3.1719e+01]])}, 6: {'step': tensor(250.), 'exp_avg': tensor([[-1.5762e+02, -1.7854e+01,  2.1367e+01,  0.0000e+00,  3.7763e-01,\n",
      "          0.0000e+00,  2.6600e+01,  0.0000e+00, -7.8873e+01, -7.5609e+01,\n",
      "          4.7515e-10, -1.2778e+01,  0.0000e+00,  0.0000e+00,  2.1798e-01,\n",
      "          0.0000e+00,  0.0000e+00, -6.6960e+01,  0.0000e+00, -3.7956e+01,\n",
      "          0.0000e+00,  7.3504e+01,  0.0000e+00,  1.0954e+01, -9.4607e+01,\n",
      "          0.0000e+00, -2.1074e+00,  3.7155e+01,  6.5905e+00,  0.0000e+00,\n",
      "          0.0000e+00,  1.0556e+01, -6.3396e+01, -7.2575e+00,  5.0181e+01,\n",
      "          0.0000e+00,  1.3231e+02,  0.0000e+00,  5.9051e+01,  0.0000e+00,\n",
      "         -1.7010e+01, -1.3678e+01,  3.0402e-10,  7.4777e+00,  0.0000e+00,\n",
      "          0.0000e+00,  2.1182e+00,  0.0000e+00,  0.0000e+00, -3.6247e+00,\n",
      "          0.0000e+00, -1.8661e+00,  0.0000e+00,  9.7956e+01,  0.0000e+00,\n",
      "          6.5101e+01,  4.3646e+00,  0.0000e+00,  7.3775e+00,  9.7279e+01,\n",
      "          1.7372e+01,  0.0000e+00,  0.0000e+00,  6.1052e+01]]), 'exp_avg_sq': tensor([[3.8883e+06, 1.8730e+04, 2.7861e+06, 0.0000e+00, 1.4863e+07, 0.0000e+00,\n",
      "         1.6205e+05, 0.0000e+00, 1.8372e+06, 2.7238e+06, 2.3667e+02, 5.0122e+04,\n",
      "         0.0000e+00, 0.0000e+00, 1.0101e+03, 0.0000e+00, 0.0000e+00, 1.4619e+06,\n",
      "         0.0000e+00, 4.5779e+04, 0.0000e+00, 1.5665e+06, 0.0000e+00, 6.2313e+06,\n",
      "         1.2104e+06, 0.0000e+00, 1.7869e+03, 1.8595e+06, 2.9036e+04, 0.0000e+00,\n",
      "         0.0000e+00, 2.0423e+06, 2.2074e+06, 6.7222e+03, 1.6543e+06, 0.0000e+00,\n",
      "         9.1320e+06, 0.0000e+00, 8.4719e+04, 0.0000e+00, 9.7440e+05, 1.7099e+06,\n",
      "         4.4140e+01, 2.2668e+04, 0.0000e+00, 0.0000e+00, 1.9740e+02, 0.0000e+00,\n",
      "         0.0000e+00, 8.2416e+05, 0.0000e+00, 1.4026e+04, 0.0000e+00, 9.5274e+05,\n",
      "         0.0000e+00, 3.7977e+06, 7.3986e+05, 0.0000e+00, 5.3481e+02, 1.2162e+06,\n",
      "         1.3722e+04, 0.0000e+00, 0.0000e+00, 1.1992e+06]])}, 7: {'step': tensor(250.), 'exp_avg': tensor([0.1394]), 'exp_avg_sq': tensor([80.9953])}}\n",
      "param_groups \t [{'lr': 0.0007, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'maximize': False, 'foreach': None, 'capturable': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7]}]\n"
     ]
    }
   ],
   "source": [
    "model = first_model\n",
    "optimizer = optimizer_first\n",
    "\n",
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "\n",
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN_BASE_model(\n",
      "  (initial_conv): GCNConv(9, 32)\n",
      "  (conv1): GCNConv(32, 32)\n",
      "  (conv2): GCNConv(32, 32)\n",
      "  (out): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n",
      "GCN_BASE_model(\n",
      "  (initial_conv): GCNConv(9, 64)\n",
      "  (conv1): GCNConv(64, 64)\n",
      "  (conv2): GCNConv(64, 64)\n",
      "  (out): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "GCN_BASE_model(\n",
      "  (initial_conv): GCNConv(9, 128)\n",
      "  (conv1): GCNConv(128, 128)\n",
      "  (conv2): GCNConv(128, 128)\n",
      "  (out): Linear(in_features=256, out_features=1, bias=True)\n",
      ")\n",
      "GCN_More_layer_model(\n",
      "  (initial_conv): GCNConv(9, 32)\n",
      "  (conv1): GCNConv(32, 32)\n",
      "  (conv2): GCNConv(32, 32)\n",
      "  (conv3): GCNConv(32, 32)\n",
      "  (out): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n",
      "GCN_More_layer_model(\n",
      "  (initial_conv): GCNConv(9, 64)\n",
      "  (conv1): GCNConv(64, 64)\n",
      "  (conv2): GCNConv(64, 64)\n",
      "  (conv3): GCNConv(64, 64)\n",
      "  (out): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "GCN_More_layer_model(\n",
      "  (initial_conv): GCNConv(9, 128)\n",
      "  (conv1): GCNConv(128, 128)\n",
      "  (conv2): GCNConv(128, 128)\n",
      "  (conv3): GCNConv(128, 128)\n",
      "  (out): Linear(in_features=256, out_features=1, bias=True)\n",
      ")\n",
      "GCN_Less_layer_model(\n",
      "  (initial_conv): GCNConv(9, 32)\n",
      "  (conv1): GCNConv(32, 32)\n",
      "  (out): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n",
      "GCN_Less_layer_model(\n",
      "  (initial_conv): GCNConv(9, 64)\n",
      "  (conv1): GCNConv(64, 64)\n",
      "  (out): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "GCN_Less_layer_model(\n",
      "  (initial_conv): GCNConv(9, 128)\n",
      "  (conv1): GCNConv(128, 128)\n",
      "  (out): Linear(in_features=256, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(first_model)\n",
    "print(second_model)\n",
    "print(third_model)\n",
    "print(forth_model)\n",
    "print(fifth_model)\n",
    "print(sixth_model)\n",
    "print(seventh_model)\n",
    "print(eighth_model)\n",
    "print(ninth_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#second set\n",
    "#first model\n",
    "m11 = GCN_BASE_model_tanh(data_num_features=data.num_features, embedding_size=32)\n",
    "PATH_m11_init = \"Save_weight/init_weight/m11.pth\"\n",
    "# m11.init_weights()\n",
    "# torch.save(m11.state_dict(), PATH_m11_init)\n",
    "m11.load_state_dict(torch.load(PATH_m11_init))\n",
    "optimizer_m11 = torch.optim.Adam(m11.parameters(), lr=0.0007)\n",
    "\n",
    "#second model\n",
    "m12 = GCN_BASE_model_tanh(data_num_features=data.num_features, embedding_size=64)\n",
    "PATH_m12_init = \"Save_weight/init_weight/m12.pth\"\n",
    "# m12.init_weights()\n",
    "# torch.save(m12.state_dict(), PATH_m12_init)\n",
    "m12.load_state_dict(torch.load(PATH_m12_init))\n",
    "optimizer_m12 = torch.optim.Adam(m12.parameters(), lr=0.0007)\n",
    "\n",
    "#third model\n",
    "m13 = GCN_BASE_model_tanh(data_num_features=data.num_features, embedding_size=128)\n",
    "PATH_m13_init = \"Save_weight/init_weight/m13.pth\"\n",
    "# m13.init_weights()\n",
    "# torch.save(m13.state_dict(), PATH_m13_init)\n",
    "m13.load_state_dict(torch.load(PATH_m13_init))\n",
    "optimizer_m13 = torch.optim.Adam(m13.parameters(), lr=0.0007)\n",
    "\n",
    "#forth model\n",
    "m14 = GCN_More_layer_model_tanh(data_num_features=data.num_features, embedding_size=32)\n",
    "PATH_m14_init = \"Save_weight/init_weight/m14.pth\"\n",
    "# m14.init_weights()\n",
    "# torch.save(m14.state_dict(), PATH_m14_init)\n",
    "m14.load_state_dict(torch.load(PATH_m14_init))\n",
    "optimizer_m14= torch.optim.Adam(m14.parameters(), lr=0.0007)\n",
    "\n",
    "#fifth model\n",
    "m15 = GCN_More_layer_model_tanh(data_num_features=data.num_features, embedding_size=64)\n",
    "PATH_m15_init = \"Save_weight/init_weight/m15.pth\"\n",
    "# m15.init_weights()\n",
    "# torch.save(m15.state_dict(), PATH_m15_init)\n",
    "m15.load_state_dict(torch.load(PATH_m15_init))\n",
    "optimizer_m15 = torch.optim.Adam(m15.parameters(), lr=0.0007)\n",
    "\n",
    "#sixth model\n",
    "m16 = GCN_More_layer_model_tanh(data_num_features=data.num_features, embedding_size=128)\n",
    "PATH_m16_init = \"Save_weight/init_weight/m16.pth\"\n",
    "# m16.init_weights()\n",
    "# torch.save(m16.state_dict(), PATH_m16_init)\n",
    "m16.load_state_dict(torch.load(PATH_m16_init))\n",
    "optimizer_m16 = torch.optim.Adam(m16.parameters(), lr=0.0007)\n",
    "\n",
    "#seventh model\n",
    "m17 = GCN_Less_layer_model_tanh(data_num_features=data.num_features, embedding_size=32)\n",
    "PATH_m17_init = \"Save_weight/init_weight/m17.pth\"\n",
    "# m17.init_weights()\n",
    "# torch.save(m17.state_dict(), PATH_m17_init)\n",
    "m17.load_state_dict(torch.load(PATH_m17_init))\n",
    "optimizer_m17 = torch.optim.Adam(m17.parameters(), lr=0.0007)\n",
    "\n",
    "#eighth model\n",
    "m18 = GCN_Less_layer_model_tanh(data_num_features=data.num_features, embedding_size=64)\n",
    "PATH_m18_init = \"Save_weight/init_weight/m18.pth\"\n",
    "# m18.init_weights()\n",
    "# torch.save(m18.state_dict(), PATH_m18_init)\n",
    "m18.load_state_dict(torch.load(PATH_m18_init))\n",
    "optimizer_m18 = torch.optim.Adam(m18.parameters(), lr=0.0007)\n",
    "\n",
    "#ninth model\n",
    "m19 = GCN_Less_layer_model_tanh(data_num_features=data.num_features, embedding_size=128)\n",
    "PATH_m19_init = \"Save_weight/init_weight/m19.pth\"\n",
    "# m19.init_weights()\n",
    "# torch.save(m19.state_dict(), PATH_m19_init)\n",
    "m19.load_state_dict(torch.load(PATH_m19_init))\n",
    "optimizer_m19 = torch.optim.Adam(m19.parameters(), lr=0.0007)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN_BASE_model_tanh(\n",
      "  (initial_conv): GCNConv(9, 32)\n",
      "  (conv1): GCNConv(32, 32)\n",
      "  (conv2): GCNConv(32, 32)\n",
      "  (out): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n",
      "GCN_BASE_model_tanh(\n",
      "  (initial_conv): GCNConv(9, 64)\n",
      "  (conv1): GCNConv(64, 64)\n",
      "  (conv2): GCNConv(64, 64)\n",
      "  (out): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "GCN_BASE_model_tanh(\n",
      "  (initial_conv): GCNConv(9, 128)\n",
      "  (conv1): GCNConv(128, 128)\n",
      "  (conv2): GCNConv(128, 128)\n",
      "  (out): Linear(in_features=256, out_features=1, bias=True)\n",
      ")\n",
      "GCN_More_layer_model_tanh(\n",
      "  (initial_conv): GCNConv(9, 32)\n",
      "  (conv1): GCNConv(32, 32)\n",
      "  (conv2): GCNConv(32, 32)\n",
      "  (conv3): GCNConv(32, 32)\n",
      "  (out): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n",
      "GCN_More_layer_model_tanh(\n",
      "  (initial_conv): GCNConv(9, 64)\n",
      "  (conv1): GCNConv(64, 64)\n",
      "  (conv2): GCNConv(64, 64)\n",
      "  (conv3): GCNConv(64, 64)\n",
      "  (out): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "GCN_More_layer_model_tanh(\n",
      "  (initial_conv): GCNConv(9, 128)\n",
      "  (conv1): GCNConv(128, 128)\n",
      "  (conv2): GCNConv(128, 128)\n",
      "  (conv3): GCNConv(128, 128)\n",
      "  (out): Linear(in_features=256, out_features=1, bias=True)\n",
      ")\n",
      "GCN_Less_layer_model_tanh(\n",
      "  (initial_conv): GCNConv(9, 32)\n",
      "  (conv1): GCNConv(32, 32)\n",
      "  (out): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n",
      "GCN_Less_layer_model_tanh(\n",
      "  (initial_conv): GCNConv(9, 64)\n",
      "  (conv1): GCNConv(64, 64)\n",
      "  (out): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "GCN_Less_layer_model_tanh(\n",
      "  (initial_conv): GCNConv(9, 128)\n",
      "  (conv1): GCNConv(128, 128)\n",
      "  (out): Linear(in_features=256, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(m11)\n",
    "print(m12)\n",
    "print(m13)\n",
    "print(m14)\n",
    "print(m15)\n",
    "print(m16)\n",
    "print(m17)\n",
    "print(m18)\n",
    "print(m19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#third set\n",
    "#first model\n",
    "m21 = GCN_BASE_model_pyra(data_num_features=data.num_features, embedding_size=32)\n",
    "PATH_m21_init = \"Save_weight/init_weight/m21.pth\"\n",
    "# m21.init_weights()\n",
    "# torch.save(m21.state_dict(), PATH_m21_init)\n",
    "m21.load_state_dict(torch.load(PATH_m21_init))\n",
    "optimizer_m21 = torch.optim.Adam(m21.parameters(), lr=0.0007)\n",
    "\n",
    "#second model\n",
    "m22 = GCN_BASE_model_pyra(data_num_features=data.num_features, embedding_size=64)\n",
    "PATH_m22_init = \"Save_weight/init_weight/m22.pth\"\n",
    "# m22.init_weights()\n",
    "# torch.save(m22.state_dict(), PATH_m22_init)\n",
    "m22.load_state_dict(torch.load(PATH_m22_init))\n",
    "optimizer_m22 = torch.optim.Adam(m22.parameters(), lr=0.0007)\n",
    "\n",
    "#third model\n",
    "m23 = GCN_BASE_model_pyra(data_num_features=data.num_features, embedding_size=128)\n",
    "PATH_m23_init = \"Save_weight/init_weight/m23.pth\"\n",
    "# m23.init_weights()\n",
    "# torch.save(m23.state_dict(), PATH_m23_init)\n",
    "m23.load_state_dict(torch.load(PATH_m23_init))\n",
    "optimizer_m23 = torch.optim.Adam(m23.parameters(), lr=0.0007)\n",
    "\n",
    "#forth model\n",
    "m24 = GCN_More_layer_model_pyra(data_num_features=data.num_features, embedding_size=32)\n",
    "PATH_m24_init = \"Save_weight/init_weight/m24.pth\"\n",
    "# m24.init_weights()\n",
    "# torch.save(m24.state_dict(), PATH_m24_init)\n",
    "m24.load_state_dict(torch.load(PATH_m24_init))\n",
    "optimizer_m24= torch.optim.Adam(m24.parameters(), lr=0.0007)\n",
    "\n",
    "#fifth model\n",
    "m25 = GCN_More_layer_model_pyra(data_num_features=data.num_features, embedding_size=64)\n",
    "PATH_m25_init = \"Save_weight/init_weight/m25.pth\"\n",
    "# m25.init_weights()\n",
    "# torch.save(m25.state_dict(), PATH_m25_init)\n",
    "m25.load_state_dict(torch.load(PATH_m25_init))\n",
    "optimizer_m25 = torch.optim.Adam(m25.parameters(), lr=0.0007)\n",
    "\n",
    "#sixth model\n",
    "m26 = GCN_More_layer_model_pyra(data_num_features=data.num_features, embedding_size=128)\n",
    "PATH_m26_init = \"Save_weight/init_weight/m26.pth\"\n",
    "# m26.init_weights()\n",
    "# torch.save(m26.state_dict(), PATH_m26_init)\n",
    "m26.load_state_dict(torch.load(PATH_m26_init))\n",
    "optimizer_m26 = torch.optim.Adam(m26.parameters(), lr=0.0007)\n",
    "\n",
    "#seventh model\n",
    "m27 = GCN_Less_layer_model_pyra(data_num_features=data.num_features, embedding_size=32)\n",
    "PATH_m27_init = \"Save_weight/init_weight/m27.pth\"\n",
    "# m27.init_weights()\n",
    "# torch.save(m27.state_dict(), PATH_m27_init)\n",
    "m27.load_state_dict(torch.load(PATH_m27_init))\n",
    "optimizer_m27 = torch.optim.Adam(m27.parameters(), lr=0.0007)\n",
    "\n",
    "#eighth model\n",
    "m28 = GCN_Less_layer_model_pyra(data_num_features=data.num_features, embedding_size=64)\n",
    "PATH_m28_init = \"Save_weight/init_weight/m28.pth\"\n",
    "# m28.init_weights()\n",
    "# torch.save(m28.state_dict(), PATH_m28_init)\n",
    "m28.load_state_dict(torch.load(PATH_m28_init))\n",
    "optimizer_m28 = torch.optim.Adam(m28.parameters(), lr=0.0007)\n",
    "\n",
    "#ninth model\n",
    "m29 = GCN_Less_layer_model_pyra(data_num_features=data.num_features, embedding_size=128)\n",
    "PATH_m29_init = \"Save_weight/init_weight/m29.pth\"\n",
    "# m29.init_weights()\n",
    "# torch.save(m29.state_dict(), PATH_m29_init)\n",
    "m29.load_state_dict(torch.load(PATH_m29_init))\n",
    "optimizer_m29 = torch.optim.Adam(m29.parameters(), lr=0.0007)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN_BASE_model_pyra(\n",
      "  (initial_conv): GCNConv(9, 32)\n",
      "  (conv1): GCNConv(32, 16)\n",
      "  (conv2): GCNConv(16, 8)\n",
      "  (out): Linear(in_features=16, out_features=1, bias=True)\n",
      ")\n",
      "GCN_BASE_model_pyra(\n",
      "  (initial_conv): GCNConv(9, 64)\n",
      "  (conv1): GCNConv(64, 32)\n",
      "  (conv2): GCNConv(32, 16)\n",
      "  (out): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n",
      "GCN_BASE_model_pyra(\n",
      "  (initial_conv): GCNConv(9, 128)\n",
      "  (conv1): GCNConv(128, 64)\n",
      "  (conv2): GCNConv(64, 32)\n",
      "  (out): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n",
      "GCN_More_layer_model_pyra(\n",
      "  (initial_conv): GCNConv(9, 32)\n",
      "  (conv1): GCNConv(32, 16)\n",
      "  (conv2): GCNConv(16, 8)\n",
      "  (conv3): GCNConv(8, 4)\n",
      "  (out): Linear(in_features=8, out_features=1, bias=True)\n",
      ")\n",
      "GCN_More_layer_model_pyra(\n",
      "  (initial_conv): GCNConv(9, 64)\n",
      "  (conv1): GCNConv(64, 32)\n",
      "  (conv2): GCNConv(32, 16)\n",
      "  (conv3): GCNConv(16, 8)\n",
      "  (out): Linear(in_features=16, out_features=1, bias=True)\n",
      ")\n",
      "GCN_More_layer_model_pyra(\n",
      "  (initial_conv): GCNConv(9, 128)\n",
      "  (conv1): GCNConv(128, 64)\n",
      "  (conv2): GCNConv(64, 32)\n",
      "  (conv3): GCNConv(32, 16)\n",
      "  (out): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n",
      "GCN_Less_layer_model_pyra(\n",
      "  (initial_conv): GCNConv(9, 32)\n",
      "  (conv1): GCNConv(32, 16)\n",
      "  (out): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n",
      "GCN_Less_layer_model_pyra(\n",
      "  (initial_conv): GCNConv(9, 64)\n",
      "  (conv1): GCNConv(64, 32)\n",
      "  (out): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n",
      "GCN_Less_layer_model_pyra(\n",
      "  (initial_conv): GCNConv(9, 128)\n",
      "  (conv1): GCNConv(128, 64)\n",
      "  (out): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(m21)\n",
    "print(m22)\n",
    "print(m23)\n",
    "print(m24)\n",
    "print(m25)\n",
    "print(m26)\n",
    "print(m27)\n",
    "print(m28)\n",
    "print(m29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forth set\n",
    "#first model\n",
    "m31 = GCN_BASE_model_tanh_pyra(data_num_features=data.num_features, embedding_size=32)\n",
    "PATH_m31_init = \"Save_weight/init_weight/m31.pth\"\n",
    "# m31.init_weights()\n",
    "# torch.save(m31.state_dict(), PATH_m31_init)\n",
    "m31.load_state_dict(torch.load(PATH_m31_init))\n",
    "optimizer_m31 = torch.optim.Adam(m31.parameters(), lr=0.0007)\n",
    "\n",
    "#second model\n",
    "m32 = GCN_BASE_model_tanh_pyra(data_num_features=data.num_features, embedding_size=64)\n",
    "PATH_m32_init = \"Save_weight/init_weight/m32.pth\"\n",
    "# m32.init_weights()\n",
    "# torch.save(m32.state_dict(), PATH_m32_init)\n",
    "m32.load_state_dict(torch.load(PATH_m32_init))\n",
    "optimizer_m32 = torch.optim.Adam(m32.parameters(), lr=0.0007)\n",
    "\n",
    "#third model\n",
    "m33 = GCN_BASE_model_tanh_pyra(data_num_features=data.num_features, embedding_size=128)\n",
    "PATH_m33_init = \"Save_weight/init_weight/m33.pth\"\n",
    "# m33.init_weights()\n",
    "# torch.save(m33.state_dict(), PATH_m33_init)\n",
    "m33.load_state_dict(torch.load(PATH_m33_init))\n",
    "optimizer_m33 = torch.optim.Adam(m33.parameters(), lr=0.0007)\n",
    "\n",
    "#forth model\n",
    "m34 = GCN_More_layer_model_tanh_pyra(data_num_features=data.num_features, embedding_size=32)\n",
    "PATH_m34_init = \"Save_weight/init_weight/m34.pth\"\n",
    "# m34.init_weights()\n",
    "# torch.save(m34.state_dict(), PATH_m34_init)\n",
    "m34.load_state_dict(torch.load(PATH_m34_init))\n",
    "optimizer_m34= torch.optim.Adam(m34.parameters(), lr=0.0007)\n",
    "\n",
    "#fifth model\n",
    "m35 = GCN_More_layer_model_tanh_pyra(data_num_features=data.num_features, embedding_size=64)\n",
    "PATH_m35_init = \"Save_weight/init_weight/m35.pth\"\n",
    "# m35.init_weights()\n",
    "# torch.save(m35.state_dict(), PATH_m35_init)\n",
    "m35.load_state_dict(torch.load(PATH_m35_init))\n",
    "optimizer_m35 = torch.optim.Adam(m35.parameters(), lr=0.0007)\n",
    "\n",
    "#sixth model\n",
    "m36 = GCN_More_layer_model_tanh_pyra(data_num_features=data.num_features, embedding_size=128)\n",
    "PATH_m36_init = \"Save_weight/init_weight/m36.pth\"\n",
    "# m36.init_weights()\n",
    "# torch.save(m36.state_dict(), PATH_m36_init)\n",
    "m36.load_state_dict(torch.load(PATH_m36_init))\n",
    "optimizer_m36 = torch.optim.Adam(m36.parameters(), lr=0.0007)\n",
    "\n",
    "#seventh model\n",
    "m37 = GCN_Less_layer_model_tanh_pyra(data_num_features=data.num_features, embedding_size=32)\n",
    "PATH_m37_init = \"Save_weight/init_weight/m37.pth\"\n",
    "# m37.init_weights()\n",
    "# torch.save(m37.state_dict(), PATH_m37_init)\n",
    "m37.load_state_dict(torch.load(PATH_m37_init))\n",
    "optimizer_m37 = torch.optim.Adam(m37.parameters(), lr=0.0007)\n",
    "\n",
    "#eighth model\n",
    "m38 = GCN_Less_layer_model_tanh_pyra(data_num_features=data.num_features, embedding_size=64)\n",
    "PATH_m38_init = \"Save_weight/init_weight/m38.pth\"\n",
    "# m38.init_weights()\n",
    "# torch.save(m38.state_dict(), PATH_m38_init)\n",
    "m38.load_state_dict(torch.load(PATH_m38_init))\n",
    "optimizer_m38 = torch.optim.Adam(m38.parameters(), lr=0.0007)\n",
    "\n",
    "#ninth model\n",
    "m39 = GCN_Less_layer_model_tanh_pyra(data_num_features=data.num_features, embedding_size=128)\n",
    "PATH_m39_init = \"Save_weight/init_weight/m39.pth\"\n",
    "# m39.init_weights()\n",
    "# torch.save(m39.state_dict(), PATH_m39_init)\n",
    "m39.load_state_dict(torch.load(PATH_m39_init))\n",
    "optimizer_m39 = torch.optim.Adam(m39.parameters(), lr=0.0007)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN_BASE_model_tanh_pyra(\n",
      "  (initial_conv): GCNConv(9, 32)\n",
      "  (conv1): GCNConv(32, 16)\n",
      "  (conv2): GCNConv(16, 8)\n",
      "  (out): Linear(in_features=16, out_features=1, bias=True)\n",
      ")\n",
      "GCN_BASE_model_tanh_pyra(\n",
      "  (initial_conv): GCNConv(9, 64)\n",
      "  (conv1): GCNConv(64, 32)\n",
      "  (conv2): GCNConv(32, 16)\n",
      "  (out): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n",
      "GCN_BASE_model_tanh_pyra(\n",
      "  (initial_conv): GCNConv(9, 128)\n",
      "  (conv1): GCNConv(128, 64)\n",
      "  (conv2): GCNConv(64, 32)\n",
      "  (out): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n",
      "GCN_More_layer_model_tanh_pyra(\n",
      "  (initial_conv): GCNConv(9, 32)\n",
      "  (conv1): GCNConv(32, 16)\n",
      "  (conv2): GCNConv(16, 8)\n",
      "  (conv3): GCNConv(8, 4)\n",
      "  (out): Linear(in_features=8, out_features=1, bias=True)\n",
      ")\n",
      "GCN_More_layer_model_tanh_pyra(\n",
      "  (initial_conv): GCNConv(9, 64)\n",
      "  (conv1): GCNConv(64, 32)\n",
      "  (conv2): GCNConv(32, 16)\n",
      "  (conv3): GCNConv(16, 8)\n",
      "  (out): Linear(in_features=16, out_features=1, bias=True)\n",
      ")\n",
      "GCN_More_layer_model_tanh_pyra(\n",
      "  (initial_conv): GCNConv(9, 128)\n",
      "  (conv1): GCNConv(128, 64)\n",
      "  (conv2): GCNConv(64, 32)\n",
      "  (conv3): GCNConv(32, 16)\n",
      "  (out): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n",
      "GCN_Less_layer_model_tanh_pyra(\n",
      "  (initial_conv): GCNConv(9, 32)\n",
      "  (conv1): GCNConv(32, 16)\n",
      "  (out): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n",
      "GCN_Less_layer_model_tanh_pyra(\n",
      "  (initial_conv): GCNConv(9, 64)\n",
      "  (conv1): GCNConv(64, 32)\n",
      "  (out): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n",
      "GCN_Less_layer_model_tanh_pyra(\n",
      "  (initial_conv): GCNConv(9, 128)\n",
      "  (conv1): GCNConv(128, 64)\n",
      "  (out): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(m31)\n",
    "print(m32)\n",
    "print(m33)\n",
    "print(m34)\n",
    "print(m35)\n",
    "print(m36)\n",
    "print(m37)\n",
    "print(m38)\n",
    "print(m39)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup dataset\n",
    "data_size = len(data)\n",
    "NUM_GRAPHS_PER_BATCH = 32\n",
    "training_set = DataLoader(data[:int(data_size * 0.7)],\n",
    "                    batch_size=NUM_GRAPHS_PER_BATCH, shuffle=True)\n",
    "test_set = DataLoader(data[int(data_size * 0.7):int(data_size * 0.85)],\n",
    "                         batch_size=NUM_GRAPHS_PER_BATCH, shuffle=True)\n",
    "validation_set = DataLoader(data[int(data_size * 0.85):],\n",
    "                         batch_size=NUM_GRAPHS_PER_BATCH, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GCN_BASE_model_tanh' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# first_model trainning\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m first_model \u001b[38;5;241m=\u001b[39m \u001b[43mGCN_BASE_model_tanh\u001b[49m(data_num_features\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mnum_features, embedding_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m)\n\u001b[0;32m      3\u001b[0m first_model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(PATH_first_model_init))\n\u001b[0;32m      4\u001b[0m optimizer_first \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(first_model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0007\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'GCN_BASE_model_tanh' is not defined"
     ]
    }
   ],
   "source": [
    "# first_model trainning\n",
    "first_model = GCN_BASE_model_tanh(data_num_features=data.num_features, embedding_size=32)\n",
    "first_model.load_state_dict(torch.load(PATH_first_model_init))\n",
    "optimizer_first = torch.optim.Adam(first_model.parameters(), lr=0.0007)\n",
    "loss_train_track_first, loss_valid_track_first, stop_at_epoch_first = train(model=first_model, optimizer=optimizer_first, loss_fn=loss_fn,\n",
    "                                                                            epochs=5, is_early_stop=False, show_result_at=1,\n",
    "                                                                            device=device, validation_set=validation_set, training_set=training_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([506, 32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6300,  0.0249,  0.1932,  ..., -0.8402,  0.3456, -0.7654],\n",
       "        [-0.6404, -0.4978, -0.2227,  ..., -0.1386,  0.2953,  0.1464],\n",
       "        [ 0.8533,  0.6839,  0.6223,  ...,  0.5807,  0.5475,  0.2509],\n",
       "        ...,\n",
       "        [ 0.3823,  0.0369,  0.7951,  ...,  0.9008,  0.5397, -0.0076],\n",
       "        [ 0.1935,  0.6556,  0.9537,  ...,  0.8938,  0.8869,  0.5325],\n",
       "        [ 0.9676, -0.7779, -0.7086,  ...,  0.0625, -0.7975,  0.6519]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# m = torch.nn.Tanh()\n",
    "# input = torch.randn(506,32)\n",
    "# print(input.shape)\n",
    "# m(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at epoch : 1 train_loss = 1223.36765625  valid_loss = 444.2113978068034\n",
      "at epoch : 2 train_loss = 218.0674462890625  valid_loss = 180.34984334309897\n",
      "at epoch : 3 train_loss = 140.02480194091797  valid_loss = 153.50049463907877\n",
      "at epoch : 4 train_loss = 119.71230773925781  valid_loss = 131.25205357869467\n",
      "at epoch : 5 train_loss = 106.41873245239258  valid_loss = 114.71997578938802\n"
     ]
    }
   ],
   "source": [
    "# first_model trainning\n",
    "first_model = GCN_BASE_model(data_num_features=data.num_features, embedding_size=32)\n",
    "first_model.load_state_dict(torch.load(PATH_first_model_init))\n",
    "optimizer_first = torch.optim.Adam(first_model.parameters(), lr=0.0007)\n",
    "loss_train_track_first, loss_valid_track_first, stop_at_epoch_first = train(model=first_model, optimizer=optimizer_first, loss_fn=loss_fn,\n",
    "                                                                            epochs=5, is_early_stop=False, show_result_at=1,\n",
    "                                                                            device=device, validation_set=validation_set, training_set=training_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case valid better case 1\n",
      "case valid better case 2\n",
      "case valid better case 3\n",
      "case valid better case 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[253.21293131510416, 219.31498962402344, 146.00571568806967]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# second_model trainning\n",
    "second_model = GCN_BASE_model(data_num_features=data.num_features, embedding_size=64)\n",
    "second_model.load_state_dict(torch.load(PATH_second_model_init))\n",
    "optimizer_second = torch.optim.Adam(second_model.parameters(), lr=0.0007)\n",
    "loss_train_track_second, loss_valid_track_second, stop_at_epoch_second = train(model=second_model, optimizer=optimizer_second, loss_fn=loss_fn,\n",
    "                                                                            epochs=5, is_early_stop=False, show_result_at=1,\n",
    "                                                                            device=device, validation_set=validation_set, training_set=training_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at epoch : 1 train_loss = 14010.541247558594  valid_loss = 7101.525227864583\n",
      "at epoch : 2 train_loss = 3068.4201904296874  valid_loss = 1198.3312072753906\n",
      "at epoch : 3 train_loss = 1000.2343969726562  valid_loss = 457.67698160807294\n",
      "at epoch : 4 train_loss = 652.530283203125  valid_loss = 422.07728068033856\n",
      "at epoch : 5 train_loss = 521.9027917480469  valid_loss = 334.9480489095052\n"
     ]
    }
   ],
   "source": [
    "# third_model trainning\n",
    "third_model = GCN_BASE_model(data_num_features=data.num_features, embedding_size=128)\n",
    "third_model.load_state_dict(torch.load(PATH_third_model_init))\n",
    "optimizer_third = torch.optim.Adam(third_model.parameters(), lr=0.0007)\n",
    "loss_train_track_third, loss_valid_track_third, stop_at_epoch_third = train(model=third_model, optimizer=optimizer_third, loss_fn=loss_fn,\n",
    "                                                                            epochs=5, is_early_stop=False, show_result_at=1,\n",
    "                                                                            device=device, validation_set=validation_set, training_set=training_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at epoch : 1 train_loss = 168668.0931640625  valid_loss = 14573.262451171875\n",
      "at epoch : 2 train_loss = 14536.6262109375  valid_loss = 9919.899820963541\n",
      "at epoch : 3 train_loss = 7700.442963867187  valid_loss = 7732.3857421875\n",
      "at epoch : 4 train_loss = 5078.977646484375  valid_loss = 4768.129150390625\n",
      "at epoch : 5 train_loss = 3945.779931640625  valid_loss = 4209.951985677083\n"
     ]
    }
   ],
   "source": [
    "# forth_model trainning\n",
    "forth_model = GCN_More_layer_model(data_num_features=data.num_features, embedding_size=32)\n",
    "forth_model.load_state_dict(torch.load(PATH_forth_model_init))\n",
    "optimizer_forth = torch.optim.Adam(forth_model.parameters(), lr=0.0007)\n",
    "loss_train_track_forth, loss_valid_track_forth, stop_at_epoch_forth = train(model=forth_model, optimizer=optimizer_forth, loss_fn=loss_fn,\n",
    "                                                                            epochs=5, is_early_stop=False, show_result_at=1,\n",
    "                                                                            device=device, validation_set=validation_set, training_set=training_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at epoch : 1 train_loss = 290317.925  valid_loss = 80146.95833333333\n",
      "at epoch : 2 train_loss = 47168.927578125  valid_loss = 33557.8056640625\n",
      "at epoch : 3 train_loss = 26031.3353125  valid_loss = 22366.338704427082\n",
      "at epoch : 4 train_loss = 18155.06140625  valid_loss = 16714.211100260418\n",
      "at epoch : 5 train_loss = 14377.90279296875  valid_loss = 15549.471842447916\n"
     ]
    }
   ],
   "source": [
    "# fifth_model trainning\n",
    "fifth_model = GCN_More_layer_model(data_num_features=data.num_features, embedding_size=64)\n",
    "fifth_model.load_state_dict(torch.load(PATH_fifth_model_init))\n",
    "optimizer_fifth = torch.optim.Adam(fifth_model.parameters(), lr=0.0007)\n",
    "loss_train_track_fifth, loss_valid_track_fifth, stop_at_epoch_fifth = train(model=fifth_model, optimizer=optimizer_fifth, loss_fn=loss_fn,\n",
    "                                                                            epochs=5, is_early_stop=False, show_result_at=1,\n",
    "                                                                            device=device, validation_set=validation_set, training_set=training_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at epoch : 1 train_loss = 653378.670625  valid_loss = 169392.13802083334\n",
      "at epoch : 2 train_loss = 79683.50765625  valid_loss = 75401.412109375\n",
      "at epoch : 3 train_loss = 46895.375390625  valid_loss = 47709.873697916664\n",
      "at epoch : 4 train_loss = 34297.579921875  valid_loss = 37001.234049479164\n",
      "at epoch : 5 train_loss = 26660.2360546875  valid_loss = 28468.814778645832\n"
     ]
    }
   ],
   "source": [
    "# sixth_model trainning\n",
    "sixth_model = GCN_More_layer_model(data_num_features=data.num_features, embedding_size=128)\n",
    "sixth_model.load_state_dict(torch.load(PATH_sixth_model_init))\n",
    "optimizer_sixth = torch.optim.Adam(sixth_model.parameters(), lr=0.0007)\n",
    "loss_train_track_sixth, loss_valid_track_sixth, stop_at_epoch_sixth = train(model=sixth_model, optimizer=optimizer_sixth, loss_fn=loss_fn,\n",
    "                                                                            epochs=5, is_early_stop=False, show_result_at=1,\n",
    "                                                                            device=device, validation_set=validation_set, training_set=training_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at epoch : 1 train_loss = 457.20014053344727  valid_loss = 54.9495644569397\n",
      "at epoch : 2 train_loss = 50.36080497741699  valid_loss = 46.65918699900309\n",
      "at epoch : 3 train_loss = 35.57845058441162  valid_loss = 30.560200055440266\n",
      "at epoch : 4 train_loss = 26.049870090484617  valid_loss = 23.178395748138428\n",
      "at epoch : 5 train_loss = 19.84479419708252  valid_loss = 23.055582523345947\n"
     ]
    }
   ],
   "source": [
    "# seventh_model trainning\n",
    "seventh_model = GCN_Less_layer_model(data_num_features=data.num_features, embedding_size=32)\n",
    "seventh_model.load_state_dict(torch.load(PATH_seventh_model_init))\n",
    "optimizer_seventh = torch.optim.Adam(seventh_model.parameters(), lr=0.0007)\n",
    "loss_train_track_seventh, loss_valid_track_seventh, stop_at_epoch_seventh = train(model=seventh_model, optimizer=optimizer_seventh, loss_fn=loss_fn,\n",
    "                                                                            epochs=5, is_early_stop=False, show_result_at=1,\n",
    "                                                                            device=device, validation_set=validation_set, training_set=training_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at epoch : 1 train_loss = 77.4163667678833  valid_loss = 28.690818468729656\n",
      "at epoch : 2 train_loss = 17.58393970489502  valid_loss = 13.077176411946615\n",
      "at epoch : 3 train_loss = 11.762789325714111  valid_loss = 11.498063882191977\n",
      "at epoch : 4 train_loss = 9.885744438171386  valid_loss = 10.528969685236612\n",
      "at epoch : 5 train_loss = 8.812910270690917  valid_loss = 10.373045921325684\n"
     ]
    }
   ],
   "source": [
    "# eighth_model trainning\n",
    "eighth_model = GCN_Less_layer_model(data_num_features=data.num_features, embedding_size=64)\n",
    "eighth_model.load_state_dict(torch.load(PATH_eighth_model_init))\n",
    "optimizer_eighth = torch.optim.Adam(eighth_model.parameters(), lr=0.0007)\n",
    "loss_train_track_eighth, loss_valid_track_eighth, stop_at_epoch_eighth = train(model=eighth_model, optimizer=optimizer_eighth, loss_fn=loss_fn,\n",
    "                                                                            epochs=5, is_early_stop=False, show_result_at=1,\n",
    "                                                                            device=device, validation_set=validation_set, training_set=training_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at epoch : 1 train_loss = 1114.9195788574218  valid_loss = 282.3285140991211\n",
      "at epoch : 2 train_loss = 152.2808544921875  valid_loss = 57.048532803853355\n",
      "at epoch : 3 train_loss = 39.998948135375976  valid_loss = 27.512378374735516\n",
      "at epoch : 4 train_loss = 26.421061401367187  valid_loss = 25.96221923828125\n",
      "at epoch : 5 train_loss = 22.711476974487304  valid_loss = 21.40555222829183\n"
     ]
    }
   ],
   "source": [
    "# ninth_model trainning\n",
    "ninth_model = GCN_Less_layer_model(data_num_features=data.num_features, embedding_size=128)\n",
    "ninth_model.load_state_dict(torch.load(PATH_ninth_model_init))\n",
    "optimizer_ninth = torch.optim.Adam(ninth_model.parameters(), lr=0.0007)\n",
    "loss_train_track_ninth, loss_valid_track_ninth, stop_at_epoch_ninth = train(model=ninth_model, optimizer=optimizer_ninth, loss_fn=loss_fn,\n",
    "                                                                            epochs=5, is_early_stop=False, show_result_at=1,\n",
    "                                                                            device=device, validation_set=validation_set, training_set=training_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8329761435263996"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sklearn.metrics.mean_squared_error(df['y_real'], df['y_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # first model\n",
    "# embedding_size = 64\n",
    "# class GCN_first_model(torch.nn.Module):\n",
    "#     def __init__(self):\n",
    "#         torch.manual_seed(seed_value)\n",
    "#         # Init parent\n",
    "#         super(GCN_first_model, self).__init__()\n",
    "\n",
    "#         # define layer\n",
    "#         self.initial_conv = GCNConv(data.num_features, embedding_size)\n",
    "#         self.conv1 = GCNConv(embedding_size, embedding_size)\n",
    "#         self.conv2 = GCNConv(embedding_size, embedding_size)\n",
    "    \n",
    "#         # define linear layer\n",
    "#         self.out = Linear(embedding_size*2, 1)\n",
    "    \n",
    "#     def init_weights(self):\n",
    "#         # Use Xavier/Glorot initialization for GCNConv layers\n",
    "#         for layer in [self.initial_conv, self.conv1, self.conv2]:\n",
    "#             if isinstance(layer, GCNConv):\n",
    "#                 # layer.reset_parameters()\n",
    "#                 if isinstance(layer, GCNConv):\n",
    "#                     init.normal_(layer.lin.weight)\n",
    "#                     if layer.bias is not None:\n",
    "#                         init.zeros_(layer.bias)\n",
    "\n",
    "#         # Initialize weights for the Linear layer\n",
    "#         init.xavier_normal_(self.out.weight)\n",
    "#         if self.out.bias is not None:\n",
    "#             init.zeros_(self.out.bias)\n",
    "\n",
    "#     def forward(self, x, edge_index, batch_index):\n",
    "        \n",
    "#         # first layer\n",
    "#         hidden = self.initial_conv(x, edge_index)\n",
    "#         hidden = F.relu(hidden)\n",
    "#         # second layer\n",
    "#         hidden = self.conv1(hidden, edge_index)\n",
    "#         hidden = F.relu(hidden)\n",
    "#         # third layer\n",
    "#         hidden = self.conv2(hidden, edge_index)\n",
    "#         hidden = F.relu(hidden)\n",
    "\n",
    "#         # global pooling\n",
    "#         hidden = torch.cat([gmp(hidden, batch_index),\n",
    "#                             gap(hidden, batch_index)], dim=1)\n",
    "                            \n",
    "\n",
    "#         # apply linear layer\n",
    "#         out = self.out(hidden)\n",
    "#         return out\n",
    "    \n",
    "\n",
    "# # second model\n",
    "# embedding_size = 32\n",
    "# class GCN_second_model(torch.nn.Module):\n",
    "#     def __init__(self):\n",
    "#         torch.manual_seed(seed_value)\n",
    "#         # Init parent\n",
    "#         super(GCN_second_model, self).__init__()\n",
    "\n",
    "#         # define layer\n",
    "#         self.initial_conv = GCNConv(data.num_features, embedding_size)\n",
    "#         self.conv1 = GCNConv(embedding_size, embedding_size)\n",
    "#         self.conv2 = GCNConv(embedding_size, embedding_size)\n",
    "    \n",
    "#         # define linear layer\n",
    "#         self.out = Linear(embedding_size*2, 1)\n",
    "\n",
    "#     def init_weights(self):\n",
    "#         # Use Xavier/Glorot initialization for GCNConv layers\n",
    "#         for layer in [self.initial_conv, self.conv1, self.conv2]:\n",
    "#             if isinstance(layer, GCNConv):\n",
    "#                 # layer.reset_parameters()\n",
    "#                 if isinstance(layer, GCNConv):\n",
    "#                     init.normal_(layer.lin.weight)\n",
    "#                     if layer.bias is not None:\n",
    "#                         init.zeros_(layer.bias)\n",
    "\n",
    "#         # Initialize weights for the Linear layer\n",
    "#         init.xavier_normal_(self.out.weight)\n",
    "#         if self.out.bias is not None:\n",
    "#             init.zeros_(self.out.bias)\n",
    "\n",
    "#     def forward(self, x, edge_index, batch_index):\n",
    "        \n",
    "#         # first layer\n",
    "#         hidden = self.initial_conv(x, edge_index)\n",
    "#         hidden = F.relu(hidden)\n",
    "#         # second layer\n",
    "#         hidden = self.conv1(hidden, edge_index)\n",
    "#         hidden = F.relu(hidden)\n",
    "#         # third layer\n",
    "#         hidden = self.conv2(hidden, edge_index)\n",
    "#         hidden = F.relu(hidden)\n",
    "\n",
    "#         # global pooling\n",
    "#         hidden = torch.cat([gmp(hidden, batch_index),\n",
    "#                             gap(hidden, batch_index)], dim=1)\n",
    "\n",
    "#         # apply linear layer\n",
    "#         out = self.out(hidden)\n",
    "#         return out\n",
    "\n",
    "# # third model\n",
    "# embedding_size = 128\n",
    "# class GCN_third_model(torch.nn.Module):\n",
    "#     def __init__(self):\n",
    "#         torch.manual_seed(seed_value)\n",
    "#         # Init parent\n",
    "#         super(GCN_third_model, self).__init__()\n",
    "\n",
    "#         # define layer\n",
    "#         self.initial_conv = GCNConv(data.num_features, embedding_size)\n",
    "#         self.conv1 = GCNConv(embedding_size, embedding_size)\n",
    "#         self.conv2 = GCNConv(embedding_size, embedding_size)\n",
    "    \n",
    "#         # define linear layer\n",
    "#         self.out = Linear(embedding_size*2, 1)\n",
    "\n",
    "#     def init_weights(self):\n",
    "#         # Use Xavier/Glorot initialization for GCNConv layers\n",
    "#         for layer in [self.initial_conv, self.conv1, self.conv2]:\n",
    "#             if isinstance(layer, GCNConv):\n",
    "#                 # layer.reset_parameters()\n",
    "#                 if isinstance(layer, GCNConv):\n",
    "#                     init.normal_(layer.lin.weight)\n",
    "#                     if layer.bias is not None:\n",
    "#                         init.zeros_(layer.bias)\n",
    "\n",
    "#         # Initialize weights for the Linear layer\n",
    "#         init.xavier_normal_(self.out.weight)\n",
    "#         if self.out.bias is not None:\n",
    "#             init.zeros_(self.out.bias)\n",
    "\n",
    "#     def forward(self, x, edge_index, batch_index):\n",
    "        \n",
    "#         # first layer\n",
    "#         hidden = self.initial_conv(x, edge_index)\n",
    "#         hidden = F.relu(hidden)\n",
    "#         # second layer\n",
    "#         hidden = self.conv1(hidden, edge_index)\n",
    "#         hidden = F.relu(hidden)\n",
    "#         # third layer\n",
    "#         hidden = self.conv2(hidden, edge_index)\n",
    "#         hidden = F.relu(hidden)\n",
    "\n",
    "#         # global pooling\n",
    "#         hidden = torch.cat([gmp(hidden, batch_index),\n",
    "#                             gap(hidden, batch_index)], dim=1)\n",
    "\n",
    "#         # apply linear layer\n",
    "#         out = self.out(hidden)\n",
    "#         return out\n",
    "    \n",
    "\n",
    "# class EarlyStopping:\n",
    "#     def __init__(self, tolerance=5, min_delta=0):\n",
    "#         self.tolerance = tolerance\n",
    "#         self.min_delta = min_delta\n",
    "#         self.counter = 0\n",
    "#         self.early_stop = False\n",
    "#         self.best_validation_loss = float('inf')\n",
    "\n",
    "#     def __call__(self, train_loss, validation_loss):\n",
    "#         if train_loss > (self.best_validation_loss - self.min_delta):\n",
    "#             self.counter = 0\n",
    "#             self.best_validation_loss = validation_loss\n",
    "\n",
    "#         elif  self.best_validation_loss - self.min_delta > train_loss  :\n",
    "#             self.best_validation_loss = validation_loss\n",
    "#             self.counter += 1\n",
    "#             print(f'case valid better case {self.counter}')\n",
    "#             if self.counter >= self.tolerance:\n",
    "#                 self.early_stop = True\n",
    "\n",
    "#         else : \n",
    "#             print('something wrong')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # training function\n",
    "# def train(model,optimizer,loss_fn,epochs:int=1000, is_early_stop:bool = True,show_result_at:int = 0):\n",
    "#     earlystop = EarlyStopping(tolerance=7,min_delta=1)\n",
    "#     train_losses_epoch = []\n",
    "#     valid_losses_epoch = []\n",
    "#     stop_at_epoch = epochs\n",
    "#     for epoch in range(epochs):\n",
    "#         model = model.to(device)\n",
    "#         train_losses = []\n",
    "#         valid_losses = []\n",
    "        \n",
    "#         #train step\n",
    "#         for batch in training_set:\n",
    "#             # Use GPU\n",
    "#             batch.to(device)\n",
    "#             # Reset gradients\n",
    "#             optimizer.zero_grad()\n",
    "#             # Passing the node features and the connection info\n",
    "#             pred  = model(batch.x.float(), batch.edge_index, batch.batch)\n",
    "#             # Calculating the loss and gradients\n",
    "#             train_loss = loss_fn(pred, batch.y)\n",
    "#             train_loss.backward()\n",
    "#             if torch.cuda.is_available() : float_train_loss = float(train_loss.cpu().detach().numpy().astype(float))\n",
    "#             else : float_train_loss = float(train_loss.detach().numpy().astype(float))\n",
    "#             train_losses.append(float_train_loss)\n",
    "#             # Update using the gradients\n",
    "#             optimizer.step()\n",
    "        \n",
    "#         #valid step\n",
    "#         model.eval()\n",
    "#         for batch in validation_set:\n",
    "#             # Use GPU\n",
    "#             batch.to(device)\n",
    "#             # Passing the node features and the connection info\n",
    "#             pred = model(batch.x.float(), batch.edge_index, batch.batch)\n",
    "#             # Calculating the loss\n",
    "#             valid_loss = loss_fn(pred, batch.y)\n",
    "#             if torch.cuda.is_available(): float_valid_loss = float(valid_loss.cpu().detach().numpy().astype(float))\n",
    "#             else : float_valid_loss = float(valid_loss.detach().numpy().astype(float))\n",
    "#             valid_losses.append(float_valid_loss)\n",
    "        \n",
    "#         #calculate average loss\n",
    "#         average_train_loss = sum(train_losses)/len(train_losses)\n",
    "#         average_valid_loss = sum(valid_losses)/len(valid_losses)\n",
    "#         train_losses_epoch.append(average_train_loss)\n",
    "#         valid_losses_epoch.append(average_valid_loss)\n",
    "#         if (show_result_at != 0) and ((epoch+1)%show_result_at == 0 ): print(f\"at epoch : {epoch} train_loss = {average_train_loss}  valid_loss = {average_valid_loss}\")\n",
    "#         if (is_early_stop):earlystop(train_loss=average_train_loss, validation_loss=average_valid_loss)\n",
    "#         if earlystop.early_stop and is_early_stop:\n",
    "#             stop_at_epoch = epoch+1\n",
    "#             print(f'result at {epoch+1} is {earlystop.early_stop}')\n",
    "#             break\n",
    "#     # test_result = test(model,loss_fn=loss_fn)\n",
    "#     return train_losses_epoch, valid_losses_epoch, stop_at_epoch\n",
    "\n",
    "# def test(model,loss_fn):\n",
    "#     test_loss_list = []\n",
    "#     for batch in test_set:\n",
    "#         batch.to(device)\n",
    "#         # Passing the node features and the connection info\n",
    "#         pred = model(batch.x.float(), batch.edge_index, batch.batch)\n",
    "#         # Calculating the loss\n",
    "#         test_loss = loss_fn(pred, batch.y)\n",
    "#         if torch.cuda.is_available(): float_test_loss = float(test_loss.cpu().detach().numpy().astype(float))\n",
    "#         else : float_test_loss = float(test_loss.detach().numpy().astype(float))\n",
    "#         test_loss_list.append(float_test_loss)\n",
    "#     average_train_loss = sum(test_loss_list)/len(test_loss_list)\n",
    "#     return average_train_loss\n",
    "\n",
    "# # def grid_search(model, loss_fn, epoch_list, embed_node_list, embed_classifire_layer):\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
